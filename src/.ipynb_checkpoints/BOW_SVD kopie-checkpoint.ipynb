{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf43c7f3",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e5b6d",
   "metadata": {},
   "source": [
    "# 0. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705a75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Packages #\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from scipy.stats import randint\n",
    "import random\n",
    "\n",
    "\n",
    "# Load TQDM to Show Progress Bars #\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "\n",
    "# Sklearn Packages #\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# NLTK Packages #\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "# Import necessary libraries for handling imbalanced data\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3216d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off warnings, just to avoid pesky messages that might cause confusion here\n",
    "# Remove when testing your own code #\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d611c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Headline</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194578</td>\n",
       "      <td>Head Line: US Patent granted to BASF SE (Delaw...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>564295</td>\n",
       "      <td>Societe Generale Launches a Next-Generation Ca...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>504138</td>\n",
       "      <td>BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91379</td>\n",
       "      <td>ASML: 4Q Earnings Snapshot</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265750</td>\n",
       "      <td>Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           Headline category\n",
       "0  194578  Head Line: US Patent granted to BASF SE (Delaw...     None\n",
       "1  564295  Societe Generale Launches a Next-Generation Ca...     None\n",
       "2  504138  BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...     None\n",
       "3   91379                         ASML: 4Q Earnings Snapshot     None\n",
       "4  265750  Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...     None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to Working Directory with Training Data # \n",
    "os.chdir(\"/Users/Artur/Desktop/thesis_HIR_versie5/coding\")\n",
    "#os.chdir(\"/Users/juarel/Desktop/studies artur/thesis_HIR/coding\")\n",
    "\n",
    "# Load Training Data #\n",
    "df_train = pd.read_csv(\"./data/train_adjusted.csv\", header = 0)\n",
    "df_test = pd.read_csv(\"./data/test_adjusted.csv\", header = 0)\n",
    "\n",
    "# inspect the data\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08324f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NameCompany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andritz AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ams AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>voestalpine AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OMV AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wienerberger AG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NameCompany\n",
       "0       Andritz AG\n",
       "1           ams AG\n",
       "2   voestalpine AG\n",
       "3           OMV AG\n",
       "4  Wienerberger AG"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data about the different companies\n",
    "companies = pd.read_excel(\"./data/companies.xlsx\", header = 0)\n",
    "companies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2d651",
   "metadata": {},
   "source": [
    "# 1. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce85e3",
   "metadata": {},
   "source": [
    "The first step when building our model is to clean the data. To perform this step, we need to define a custom tokenizer that will serve as input in our vectorizers. This tokenizer needs to fulfill the following criteria:\n",
    "\n",
    "1. We convert the strings to lowercase\n",
    "2. We remove currency symbols\n",
    "3. We remove punctuation from the text\n",
    "4. We remove English stopwords from the text as these do not provide any information to our model\n",
    "5. We remove words that with information linked to a specific company\n",
    "6. We remove words that consist out of a single character\n",
    "7. We lemmatize the words to reduce the words to their base form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca939d39",
   "metadata": {},
   "source": [
    "#### Create a list with words linked to a specific company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4bbf7",
   "metadata": {},
   "source": [
    "First, we create a set of all the unique words that could be linked to a company. These are the full company names (including legal suffixes) of which part were used to retrieve the newswires and press releases from the NexisUni database. \n",
    "\n",
    "Then, we want to determine the set of words that does not contain any information about the company, such as legal prefixes. Therefore, we inspect which words are most frequently used in the names of the companies. When we inspected the results, we saw 1021 of the 1113 words were only used once in all the company names. These words can be seen as to company specific and will be removed from our headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced3a84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1137"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a list with the companies names to use in the tokenizer\n",
    "# Do not use this information in your model\n",
    "company_info = set()\n",
    "\n",
    "for name in companies['NameCompany']:\n",
    "    name = name.lower()\n",
    "    words = name.split()\n",
    "    company_info.update(words)\n",
    "\n",
    "len(company_info) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6a899",
   "metadata": {},
   "source": [
    "Determine a set of words that does not contain any information about the company:\n",
    "\n",
    "1. First, I convert the company names into lowercase and split the words. These results are stored in the column 'cleaned_name'. \n",
    "2. Then, I retrieve all these words and store them in the array 'company_names_array'. Note that these are not unique words, but just all the cleaned words from each company joined into one array.\n",
    "3. Next, I store the frequency of each word in a dataframe. \n",
    "4. Finally, I can determine which words are to company specific to be included in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43d118ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NameCompany</th>\n",
       "      <th>cleaned_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andritz AG</td>\n",
       "      <td>[andritz, ag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ams AG</td>\n",
       "      <td>[ams, ag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>voestalpine AG</td>\n",
       "      <td>[voestalpine, ag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OMV AG</td>\n",
       "      <td>[omv, ag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wienerberger AG</td>\n",
       "      <td>[wienerberger, ag]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NameCompany        cleaned_name\n",
       "0       Andritz AG       [andritz, ag]\n",
       "1           ams AG           [ams, ag]\n",
       "2   voestalpine AG   [voestalpine, ag]\n",
       "3           OMV AG           [omv, ag]\n",
       "4  Wienerberger AG  [wienerberger, ag]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a list with only the companies names\n",
    "def company_name_tokenizer(name):\n",
    "    # Remove special characters and digits\n",
    "    name = re.sub(r\"[^\\w\\s]\", \"\", name)\n",
    "    \n",
    "    # Convert the name to lowercase\n",
    "    name = name.lower()\n",
    "    \n",
    "    # Split the name into individual words\n",
    "    words = name.split()\n",
    "    \n",
    "    return words\n",
    "\n",
    "companies['cleaned_name'] = companies['NameCompany'].apply(company_name_tokenizer)\n",
    "companies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfcb00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the values from the cleaned company names and store them in an array\n",
    "company_names_array = np.concatenate(companies['cleaned_name'].values)\n",
    "\n",
    "# Count the frequency of each word in the array\n",
    "frequent_company_info = np.unique(company_names_array, return_counts=True)\n",
    "\n",
    "# Store the results in da dataframe\n",
    "word_frequencies = pd.DataFrame({'Word': frequent_company_info[0], \n",
    "                                'Count': frequent_company_info[1]})\n",
    "\n",
    "# Sort the dataframe in descending order by the 'Count' column\n",
    "word_frequencies = word_frequencies.sort_values('Count', ascending=False)\n",
    "#word_frequencies['Count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befaea1f",
   "metadata": {},
   "source": [
    "Create a set of the words that are not linked to a specific company. In other terms, words that were used more than once in a company description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9e25601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe based on the count threshold\n",
    "general_voc = word_frequencies[word_frequencies['Count'] >= 2]['Word'].tolist()\n",
    "\n",
    "# Create a set from the filtered values\n",
    "general_voc = set(general_voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11438557",
   "metadata": {},
   "source": [
    "Remove these words from the initial set of words with all the company information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91255753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove these words from the set company info\n",
    "company_info = company_info.difference(general_voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaef60a",
   "metadata": {},
   "source": [
    "Next, define the customer tokenizer that will be used as input in our vectorizers. Therefore, we use the information in company_info that we have just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a7d1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob_tokenizer(str_input):\n",
    "    \n",
    "    # Convert list to string\n",
    "    input_str = str_input\n",
    "    if isinstance(input_str, list):\n",
    "        input_str = ' '.join(input_str)\n",
    "        \n",
    "    # Remove currency symbols\n",
    "    str_input = re.sub(r'\\$|£|€', '', str_input)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    str_input = str_input.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Define stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Tokenize text\n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    \n",
    "    # Remove numbers, stop words, company information and words with one character\n",
    "    words = [word for word in tokens if not re.match('^\\d+$', word) and word not in stop_words\n",
    "                                        and word not in company_info and len(word) > 1]\n",
    "\n",
    "    \n",
    "    # Lemmatize words\n",
    "    words = [Word(word).lemmatize() for word in words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d24788e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_headline</th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[head, u, patent, granted, se, delaware, may, ...</td>\n",
       "      <td>Head Line: US Patent granted to BASF SE (Delaw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[societe, generale, launch, nextgeneration, ca...</td>\n",
       "      <td>Societe Generale Launches a Next-Generation Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[plc, form, communication]</td>\n",
       "      <td>BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4q, earnings, snapshot]</td>\n",
       "      <td>ASML: 4Q Earnings Snapshot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[form, investment, manager, group, plc]</td>\n",
       "      <td>Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43249</th>\n",
       "      <td>[system, asa, tom, purchase, share]</td>\n",
       "      <td>Tomra Systems ASA: TOM: Purchase of own shares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43250</th>\n",
       "      <td>[swiss, federal, institute, intellectual, gran...</td>\n",
       "      <td>Swiss Federal Institute of Intellectual Proper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43251</th>\n",
       "      <td>[icon, pfizer, join, addplan, df, consortiumne...</td>\n",
       "      <td>ICON: Pfizer and Roche Join ADDPLAN DF Consort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43252</th>\n",
       "      <td>[plc, transaction, share]</td>\n",
       "      <td>Rio Tinto PLC Transaction in Own Shares -3-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43253</th>\n",
       "      <td>[building, capacity, front, generation, epigen...</td>\n",
       "      <td>Roche Building Capacity To Front Next Generati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43254 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_headline  \\\n",
       "0      [head, u, patent, granted, se, delaware, may, ...   \n",
       "1      [societe, generale, launch, nextgeneration, ca...   \n",
       "2                             [plc, form, communication]   \n",
       "3                               [4q, earnings, snapshot]   \n",
       "4                [form, investment, manager, group, plc]   \n",
       "...                                                  ...   \n",
       "43249                [system, asa, tom, purchase, share]   \n",
       "43250  [swiss, federal, institute, intellectual, gran...   \n",
       "43251  [icon, pfizer, join, addplan, df, consortiumne...   \n",
       "43252                          [plc, transaction, share]   \n",
       "43253  [building, capacity, front, generation, epigen...   \n",
       "\n",
       "                                                Headline  \n",
       "0      Head Line: US Patent granted to BASF SE (Delaw...  \n",
       "1      Societe Generale Launches a Next-Generation Ca...  \n",
       "2      BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...  \n",
       "3                             ASML: 4Q Earnings Snapshot  \n",
       "4      Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...  \n",
       "...                                                  ...  \n",
       "43249     Tomra Systems ASA: TOM: Purchase of own shares  \n",
       "43250  Swiss Federal Institute of Intellectual Proper...  \n",
       "43251  ICON: Pfizer and Roche Join ADDPLAN DF Consort...  \n",
       "43252        Rio Tinto PLC Transaction in Own Shares -3-  \n",
       "43253  Roche Building Capacity To Front Next Generati...  \n",
       "\n",
       "[43254 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the cleaned data\n",
    "df_train['cleaned_headline'] = df_train['Headline'].apply(textblob_tokenizer)\n",
    "\n",
    "# check the data\n",
    "df_train[[\"cleaned_headline\", \"Headline\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9b1ee87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      19094\n",
       "2       4144\n",
       "3       1889\n",
       "4       1081\n",
       "5        726\n",
       "       ...  \n",
       "348        1\n",
       "350        1\n",
       "351        1\n",
       "367        1\n",
       "206        1\n",
       "Name: Count, Length: 385, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words = np.concatenate(df_train['cleaned_headline'].values)\n",
    "word_counts = Counter(words)\n",
    "# Convert word_counts dictionary to a DataFrame\n",
    "df_word_counts = pd.DataFrame.from_dict(word_counts, orient='index', columns=['Count'])\n",
    "df_word_counts = df_word_counts.sort_values(by='Count', ascending=False)\n",
    "df_word_counts['Count'].value_counts() # Indicates 31 978 unique words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb86cefd",
   "metadata": {},
   "source": [
    "#### define functions needed in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccab087",
   "metadata": {},
   "source": [
    "Before we continue, we first define some useful functions and parameters that we will need later in this notebook:\n",
    "\n",
    "1. get_classification_metrics: Create a function that return the classification metrics for each model. The precision, recall and f1 score are all determined using the average value of all classes, without adjusting weights to these classes.\n",
    "\n",
    "2. create_results_df(): Create a function that creates a dataframe where the main classification metrics can be stored for each model.\n",
    "\n",
    "3. Define the number of splits, the stratified cross validator to ensure class frequencies are considered, and the scoring metric.\n",
    "\n",
    "4. Define a function that trains the defined model, depending on the vectorizer, the input data, the classifier and its parameter grid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faf61e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Function that returns classication metrics\n",
    "def get_classification_metrics(y_true, y_pred):\n",
    "    # Calculate Model Performance Metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96304f23",
   "metadata": {},
   "source": [
    "#2. Function that stores classifcation results \n",
    "def create_results_df(model_name):\n",
    "    \n",
    "    # Create an empty DataFrame with the model name as the index\n",
    "    results_df = pd.DataFrame(index=[model_name])\n",
    "\n",
    "    # Add columns for the metrics\n",
    "    columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    for col in columns:\n",
    "        results_df[col] = 0\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4703149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe to store the results of all the models\n",
    "results_all_df = pd.DataFrame()\n",
    "\n",
    "# Add columns for the metrics\n",
    "columns = ['vectorizer', 'FS', 'classifier', 'resampling','accuracy', 'precision', 'recall', 'f1']\n",
    "for col in columns:\n",
    "    results_all_df[col] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d97903e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize the stratified k-fold object\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42) # ensures class balances are kept\n",
    "\n",
    "# Define the scoring metric\n",
    "scoring = make_scorer(f1_score, average= 'macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dce7f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the independent and dependent variables\n",
    "X_train = df_train['Headline']\n",
    "X_test = df_test['Headline']\n",
    "\n",
    "y_train = df_train['category']\n",
    "y_test = df_test['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0615a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dictionary to store the optimal parameters\n",
    "best_params_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab34db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(name, model, param_grid, X_train, X_test, y_train, y_test,\n",
    "                       vectorizer, FS, classifier, resampling):\n",
    "    \n",
    "    # Define a seed value\n",
    "    random.seed(7)\n",
    "        \n",
    "    # Perform the grid search using cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=skf, scoring=scoring)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model and its hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Store the best parameters for the current category in the dictionary\n",
    "    best_params_dict[name] = best_params\n",
    "    print(f'best parameters: {best_params}')\n",
    "\n",
    "    # Retrain the best model with the whole training set\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate the probabilities (not for SVM as this is not possible)\n",
    "    if classifier != 'SVM':\n",
    "        y_pred_proba = best_model.predict_proba(X_test)\n",
    "        \n",
    "        # Find the highest probability for each observation\n",
    "        highest_prob = np.amax(y_pred_proba, axis = 1)\n",
    "    \n",
    "        # Create a DataFrame with test observations, highest probabilities, and predicted classes\n",
    "        predictions_df = pd.DataFrame({'Observation_nr': y_test.index, 'Probability': highest_prob, 'Prediction': y_pred})\n",
    "        \n",
    "    else:\n",
    "        # Create a DataFrame with test observations and predicted classes\n",
    "        predictions_df = pd.DataFrame({'Observation_nr': y_test.index, 'Prediction': y_pred})\n",
    "        \n",
    "    # Store the final predictions with its probability for the test set\n",
    "    predictions_df.to_csv(f'./Output/predictions/{name}.csv', index = False, header = True)\n",
    "    #predictions_df.to_excel(f'./Output/predictions/{name}.xlsx', index = False, header = True)\n",
    "\n",
    "    # Calculate the classification metrics\n",
    "    accuracy, precision, recall, f1 = get_classification_metrics(y_test, y_pred)\n",
    "    \n",
    "    # print the results\n",
    "    print(f'Results for {name}:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1: {f1}')\n",
    "    \n",
    "    # add the results to the dataframe with all the results\n",
    "    results_all_df.loc[name] = [vectorizer, FS, classifier, resampling, accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c12a88",
   "metadata": {},
   "source": [
    "# 2. Vectorizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c55ca4",
   "metadata": {},
   "source": [
    "In this notebook, I will test the performance of two vectorizers to transform the textual data into numerical representations. For each vectorizer, I will test 5 base classifiers. Further, will try to adress the class imbalance issue in the dataset with two resampling techniques. For each base classifier, I will train the model once without resampling technique, once with random undersampling and once with oversampling through SMOTE. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc61da4",
   "metadata": {},
   "source": [
    "## 2.1 Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82774a3f",
   "metadata": {},
   "source": [
    "The first vectorizer that we will use to transform our textual data into numerical presentations is the bag of words procedure or BOW. In this approach, each headline is treated as a collection of individual words. For each feature of the model, each document has a zero or one score indicating if the feature (=the word) is present in the headline. This is a simple and inexpensive approach to represent textual data into a numerical form. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d50f03",
   "metadata": {},
   "source": [
    "Define the parameters of the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04cbfa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum Document Frequency -- Minimum number of times a word needs to occur to be considered #\n",
    "MINDF = 2\n",
    "\n",
    "# Maximum Document Frequency -- Maximum share of documents where a word needs to occur to be considered #\n",
    "MAXDF = 0.9\n",
    "\n",
    "# Maximum number of features we would want to consider -- ranked by most frequently occuring #\n",
    "MF= 10000\n",
    "\n",
    "# NGrams -- Number of Word Pairs. Takes the form (Min, Max). E.g. (1, 2) means single words and word pairs # \n",
    "NGrams = (1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab74ed0",
   "metadata": {},
   "source": [
    "Define the vectorizer itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "454fb3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the vectorizer\n",
    "vec_bow = CountVectorizer(max_features= MF,\n",
    "                          min_df = MINDF,\n",
    "                          max_df = MAXDF,\n",
    "                          ngram_range=(1, 2),\n",
    "                          tokenizer=textblob_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9b08a",
   "metadata": {},
   "source": [
    "Transform the textual data into numerical representations with the BOW vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3da4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the BOW vectorizer (train on training data and transform test set after)\n",
    "X_train_bow = vec_bow.fit_transform(X_train)\n",
    "X_test_bow = vec_bow.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2c76a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43254, 10000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4848b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dadc9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Convert the sparse matrix to a dense array\n",
    "X_train_bow_arr = X_train_bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e923f644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['None', 'None', 'None', ..., 'Strategic alliance', 'None', 'None'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_arr = y_train.values\n",
    "y_train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "97a81559",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [4000, 5000, 6000, 7000, 8000, 9000]\n",
    "\n",
    "# get a list of models\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    for i in values:\n",
    "        steps = [('svd', TruncatedSVD(n_components=i)), ('m', LogisticRegression())]\n",
    "        models[str(i)] = Pipeline(steps=steps)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a40be257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    scores = cross_val_score(model, X_train_bow_arr, y, scoring= scoring, cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "de7d7c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">4000 0.461 (0.023)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-3713875d9d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_bow_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-80-64e9e3f0ce45>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_bow_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X_train_bow_arr, y_train_arr)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d32638f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot model performance for comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53023152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
