{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf43c7f3",
   "metadata": {},
   "source": [
    "# D. Pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e7241",
   "metadata": {},
   "source": [
    "In this notebook, I used word embeddings to transform my textual data into numerical represenations. For this purpose, I used the data was cleaned in the notebook 'B. Vectorization' and that can be found in the gold_data folder. Further, I use the same base classifiers and resampling techniques that I used in the previous notebook.\n",
    "\n",
    "First, I trained a Word2Vec model (both the continuous bag of words and the skipgram implementation) to transform my textual data. Then, I used Glove embeddings for text represenation. However, as I only have a limited dataset to train embedding models, I aslo used pretrained embedding models. Then, I could use these pretrained embeddings to transform my train and test set and train my models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e5b6d",
   "metadata": {},
   "source": [
    "# 0. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705a75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Packages #\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from scipy.stats import randint\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Sklearn Packages #\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# NLTK Packages #\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Import necessary libraries for handling imbalanced data\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Embedding related imports\n",
    "import sys\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "import spacy.cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23076e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn of warnings, just to avoid pesky messages that might cause confusion here\n",
    "# Remove when testing your own code #\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d611c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Headline</th>\n",
       "      <th>category</th>\n",
       "      <th>cleaned_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194578</td>\n",
       "      <td>Head Line: US Patent granted to BASF SE (Delaw...</td>\n",
       "      <td>None</td>\n",
       "      <td>head u patent granted se delaware may titled c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>564295</td>\n",
       "      <td>Societe Generale Launches a Next-Generation Ca...</td>\n",
       "      <td>None</td>\n",
       "      <td>societe generale launch nextgeneration card in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>504138</td>\n",
       "      <td>BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...</td>\n",
       "      <td>None</td>\n",
       "      <td>plc form communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91379</td>\n",
       "      <td>ASML: 4Q Earnings Snapshot</td>\n",
       "      <td>None</td>\n",
       "      <td>4q earnings snapshot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265750</td>\n",
       "      <td>Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...</td>\n",
       "      <td>None</td>\n",
       "      <td>form investment manager group plc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           Headline category  \\\n",
       "0  194578  Head Line: US Patent granted to BASF SE (Delaw...     None   \n",
       "1  564295  Societe Generale Launches a Next-Generation Ca...     None   \n",
       "2  504138  BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...     None   \n",
       "3   91379                         ASML: 4Q Earnings Snapshot     None   \n",
       "4  265750  Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...     None   \n",
       "\n",
       "                                    cleaned_headline  \n",
       "0  head u patent granted se delaware may titled c...  \n",
       "1  societe generale launch nextgeneration card in...  \n",
       "2                             plc form communication  \n",
       "3                               4q earnings snapshot  \n",
       "4                  form investment manager group plc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to Working Directory with Training Data # \n",
    "#os.chdir(\"/Users/Artur/Desktop/thesis_HIR_versie5/coding\")\n",
    "os.chdir(\"/Users/juarel/Desktop/studies artur/thesis_HIR/coding\")\n",
    "\n",
    "# Load the preprocessed data #\n",
    "df_train = pd.read_csv(\"./data/gold_data/train.csv\", header = 0)\n",
    "df_test = pd.read_csv(\"./data/gold_data/test.csv\", header = 0)\n",
    "\n",
    "# inspect the data\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb86cefd",
   "metadata": {},
   "source": [
    "# 1. Define functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccab087",
   "metadata": {},
   "source": [
    "Before we continue, we first define some useful functions and parameters that we use throughout this notebook. The first four functions and parameters were also used and defined in the previous notebook.\n",
    "\n",
    "1. get_classification_metrics: Create a function that return the classification metrics for each model. The precision, recall and f1 score are all determined using the average value of all classes, without adjusting weights to these classes.\n",
    "\n",
    "2. Define a dataframe to store the results of the different models. Moreover, also define a dictionary that stores the best parameters for each model.\n",
    "\n",
    "3. Define the number of splits, the stratified cross validator to ensure class frequencies are considered, and the scoring metric based on the average F1 score. We use an F1 score as scoring metric as accuracy is not a good evaluation metric in our case.\n",
    "\n",
    "4. Define a function that trains the defined model, the input data, the classifier and its parameter grid. Besides, it will also take 4 parameters as input that give more information about the model that is being trained. This is usefull for the storage of the performance of the different algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab5f50",
   "metadata": {},
   "source": [
    "New functions specific to the embedding notebook:\n",
    "\n",
    "5. Create a function to create embeddings based on a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf61e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Function that returns classication metrics\n",
    "def get_classification_metrics(y_true, y_pred):\n",
    "    \n",
    "    # Calculate Model Performance Metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4703149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create an empty dataframe to store the results of all the models\n",
    "results_all_df = pd.DataFrame()\n",
    "\n",
    "# Add columns for the metrics\n",
    "columns = ['vectorizer', 'FS', 'classifier', 'resampling','accuracy', 'precision', 'recall', 'f1']\n",
    "for col in columns:\n",
    "    results_all_df[col] = 0\n",
    "\n",
    "# create an empty dictionary to store the optimal parameters\n",
    "best_params_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d97903e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define different parameters\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize the stratified k-fold object\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42) # ensures class balances are kept\n",
    "\n",
    "# Define the scoring metric\n",
    "scoring = make_scorer(f1_score, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab34db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define a function to train and evaluate the different models\n",
    "def perform_grid_search(name, model, param_grid, X_train, X_test, y_train, y_test,\n",
    "                       vectorizer, FS, classifier, resampling):\n",
    "    \n",
    "    # Define a seed value\n",
    "    random.seed(7)\n",
    "        \n",
    "    # Perform the grid search using cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=skf, scoring=scoring)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model and its hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Store the best parameters for the current category in the dictionary\n",
    "    best_params_dict[name] = best_params\n",
    "    print(f'best parameters: {best_params}')\n",
    "\n",
    "    # Retrain the best model with the whole training set\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate the probabilities (not for SVM as this is not possible)\n",
    "    if classifier != 'SVM':\n",
    "        y_pred_proba = best_model.predict_proba(X_test)\n",
    "        \n",
    "        # Find the highest probability for each observation\n",
    "        highest_prob = np.amax(y_pred_proba, axis = 1)\n",
    "    \n",
    "        # Create a DataFrame with test observations, highest probabilities, and predicted classes\n",
    "        predictions_df = pd.DataFrame({'Observation_nr': y_test.index, 'Probability': highest_prob, 'Prediction': y_pred})\n",
    "        \n",
    "    else:\n",
    "        # Create a DataFrame with test observations and predicted classes\n",
    "        predictions_df = pd.DataFrame({'Observation_nr': y_test.index, 'Prediction': y_pred})\n",
    "        \n",
    "    # Store the final predictions with its probability for the test set\n",
    "    predictions_df.to_csv(f'./Output/predictions/{name}.csv', index = False, header = True)\n",
    "    #predictions_df.to_excel(f'./Output/predictions/{name}.xlsx', index = False, header = True)\n",
    "\n",
    "    # Calculate the classification metrics\n",
    "    accuracy, precision, recall, f1 = get_classification_metrics(y_test, y_pred)\n",
    "    \n",
    "    # print the results\n",
    "    print(f'Results for {name}:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1: {f1}')\n",
    "    \n",
    "    # add the results to the dataframe with all the results\n",
    "    results_all_df.loc[name] = [vectorizer, FS, classifier, resampling, accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df299197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define a function to transform the data into embeddings based on a pretrained model\n",
    "def vectorize_pretrained(headline, pre_trained_model, size):\n",
    "\n",
    "    # Split the headline into individual words\n",
    "    words = headline.split()\n",
    "\n",
    "    # Retrieve word embedding for each word in the headline\n",
    "    words_vecs = [pre_trained_model[word] for word in words if word in pre_trained_model]\n",
    "\n",
    "    # If no word vectors are found (i.e., no matching words in the pretrained model),\n",
    "    # return a zero vector of the specified dimension\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(size)\n",
    "\n",
    "    # Convert the list of word vectors into a numpy array and average across word vectors\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    mean_vector = words_vecs.mean(axis=0)\n",
    "\n",
    "    return mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab6ad650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the independent and dependent variables\n",
    "X_train = df_train['cleaned_headline']\n",
    "X_test = df_test['cleaned_headline']\n",
    "\n",
    "y_train = df_train['category']\n",
    "y_test = df_test['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f222d5",
   "metadata": {},
   "source": [
    "# 3. Pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a63a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vectorizer method\n",
    "vectorizer = 'pretrained'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9af000",
   "metadata": {},
   "source": [
    "## 3.1 Google news embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a86bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define type of pretrained embedding model\n",
    "FS = 'google news'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18532cc4",
   "metadata": {},
   "source": [
    "Uses continious skipgram: http://vectors.nlpl.eu/repository/?ref=blog.paperspace.com\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/03/pretrained-word-embeddings-nlp/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "122e44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if downloaded offline\n",
    "google_news = KeyedVectors.load_word2vec_format('/Users/juarel/Desktop/studies artur/thesis_HIR/big files/google/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "#google_news = KeyedVectors.load_word2vec_format('/Users/Artur/Desktop/thesis_HIR_versie5/big files/google/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62d9e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the \"word2vec-google-news-300\" embeddings if not downloaded ofline\n",
    "#google_news = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c536d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings of the train and test set based on the pretrained google_news model\n",
    "X_train_google_news = np.vstack([vectorize_pretrained(headline, google_news, 300) for headline in X_train])\n",
    "X_test_google_news = np.vstack([vectorize_pretrained(headline, google_news, 300) for headline in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0ad320",
   "metadata": {},
   "source": [
    "### 3.1.1 Without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c653c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cd2ef9",
   "metadata": {},
   "source": [
    "#### A. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "406102c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_log_w'\n",
    "classifier = 'logR'\n",
    "\n",
    "# Initialize the classifier\n",
    "logreg = LogisticRegression(random_state = 7)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_log = {\n",
    "    'penalty': ['None', 'l2'], # normal or ridge regression\n",
    "    'C': [0.1, 1, 10]          # The inverse penalization term (smaller is higher penalization)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "806626e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Results for google_log_w:\n",
      "Accuracy: 0.9151711378353377\n",
      "Precision: 0.4944273511263321\n",
      "Recall: 0.34781010828554143\n",
      "F1: 0.40113627754245584\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_google_news, X_test_google_news, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd72fe4",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75bb1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_DT_w'\n",
    "classifier = 'DT'\n",
    "\n",
    "# Initialize the classifier\n",
    "tree = DecisionTreeClassifier(random_state = 7)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_DT = {\n",
    "    'criterion': ['gini'],          # Define the splitting criteria: Gini index for node impurity\n",
    "    'min_samples_leaf': [1, 2],     # Define the minimum number of samples required to be at leaf node\n",
    "    'max_features': [None]  # Define the number of features to consider when looking for the best split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e081c2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1}\n",
      "Results for google_DT_w:\n",
      "Accuracy: 0.8480111008325625\n",
      "Precision: 0.17567993031848514\n",
      "Recall: 0.18983106229385277\n",
      "F1: 0.18191737188918056\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_google_news, X_test_google_news, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9df38",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffa7df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_svm_w'\n",
    "classifier = 'SVM'\n",
    "\n",
    "# Initialize the classifier\n",
    "svm = SVC(random_state = 7)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100], # inverse regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf'], # what type of kernel need to be used (rbf = radial kernel)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f50d3c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Results for google_svm_w:\n",
      "Accuracy: 0.9238667900092506\n",
      "Precision: 0.5922298784096163\n",
      "Recall: 0.4080671016213115\n",
      "F1: 0.47197667821066425\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_google_news, X_test_google_news, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6b6c9",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa9df9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_rf_w'\n",
    "classifier = 'RF'\n",
    "\n",
    "# Initialize the classifier\n",
    "rfc = RandomForestClassifier(random_state = 7, n_jobs = -1)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'criterion': ['gini'],          # Define the splitting criteria: Gini index for node impurity\n",
    "    'n_estimators': [100, 500],     # the number of trees to use when building the model\n",
    "    'min_samples_leaf': [1, 2],     # Define the minimum number of samples required to be at leaf node\n",
    "    'max_features': ['sqrt']        # Define the number of features to consider when looking for the best split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75a6e324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "Results for google_rf_w:\n",
      "Accuracy: 0.9049028677150787\n",
      "Precision: 0.6042766768026284\n",
      "Recall: 0.1183776120621839\n",
      "F1: 0.15245559205058493\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_google_news, X_test_google_news, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd16f14",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "431a6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_ada_w'\n",
    "classifier = 'ADA'\n",
    "\n",
    "# Initialize decision tree base estimator for AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(random_state = 7)\n",
    "\n",
    "# Initialize AdaBoost classifier\n",
    "ada = AdaBoostClassifier(base_estimator = base_estimator, random_state = 7)\n",
    "\n",
    "# Define parameter grid for AdaBoost\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [50, 100],   # the maximum number of estimators before boosting is terminated\n",
    "    'learning_rate': [0.01, 0.1], # weight applied to each classifier at boosting iteration\n",
    "                                      # A higher learning rate increases the contribution of each classifier. \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a17ec368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "Results for google_ada_w:\n",
      "Accuracy: 0.903422756706753\n",
      "Precision: 0.40712695220892786\n",
      "Recall: 0.14943771078499718\n",
      "F1: 0.18998739893219468\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_google_news, X_test_google_news, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be21bc",
   "metadata": {},
   "source": [
    "### 3.1.2 With undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e858dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Und'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db5e8085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categories and the maximum number of samples\n",
    "categories = df_train[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65c4b7",
   "metadata": {},
   "source": [
    "#### Random undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e50ee8",
   "metadata": {},
   "source": [
    "Again, we used the same undersampling strategy as we used in the notebook 'Vectorization'. We used random undersampling and reduced the imbalance ratio to 4:1 for each category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9082d9e",
   "metadata": {},
   "source": [
    "#### Second strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f759f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of samples in the biggest minority category\n",
    "rus_n = df_train['category'].value_counts().sort_values(ascending=False)[1]\n",
    "\n",
    "# Dictionary to store the actual maximum imbalance per class for undersampling\n",
    "max_imbalance_u = {}\n",
    "\n",
    "# Calculate the actual maximum imbalance for each class\n",
    "for category in categories:\n",
    "    if category == 'None':\n",
    "        max_imbalance_u[category] = rus_n\n",
    "    else:\n",
    "        # Set the actual maximum to the number of available samples\n",
    "        max_imbalance_u[category] = y_train.value_counts()[category]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9428c36c",
   "metadata": {},
   "source": [
    "#### Second strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bdd72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random undersampler with maximum imbalance\n",
    "undersampler = RandomUnderSampler(sampling_strategy = max_imbalance_u, random_state = 7)\n",
    "\n",
    "# Undersample the data\n",
    "X_train_google_news_und, y_train_google_news_und = undersampler.fit_resample(X_train_google_news, y_train)\n",
    "#y_train_cbow_und.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad9fea",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "380cb566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_log_u'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95558221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 1, 'penalty': 'l2'}\n",
      "Results for google_log_u:\n",
      "Accuracy: 0.8086031452358927\n",
      "Precision: 0.3003106892441716\n",
      "Recall: 0.6290692503922747\n",
      "F1: 0.3898184671430985\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_google_news_und, X_test_google_news,\n",
    "                    y_train_google_news_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e66e5",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e514d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_DT_u'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2f75029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1}\n",
      "Results for google_DT_u:\n",
      "Accuracy: 0.5360777058279371\n",
      "Precision: 0.12199110229967723\n",
      "Recall: 0.30212374019055194\n",
      "F1: 0.13961655818685964\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_google_news_und, X_test_google_news,\n",
    "                    y_train_google_news_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b27818",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "067a8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_svm_u'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b18dba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Results for google_svm_u:\n",
      "Accuracy: 0.8172062904717854\n",
      "Precision: 0.3124788808488373\n",
      "Recall: 0.6585206426374626\n",
      "F1: 0.4059688202168255\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_google_news_und, X_test_google_news,\n",
    "                    y_train_google_news_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20cf92b",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fa72444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_rf_u'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "810c290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 500}\n",
      "Results for google_rf_u:\n",
      "Accuracy: 0.8000925069380204\n",
      "Precision: 0.3754786739319368\n",
      "Recall: 0.45722451044908935\n",
      "F1: 0.3429789344635923\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_google_news_und, X_test_google_news,\n",
    "                    y_train_google_news_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41631fd",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f83f948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_ada_u'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c540522b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Results for google_ada_u:\n",
      "Accuracy: 0.6430157261794635\n",
      "Precision: 0.15116101389775635\n",
      "Recall: 0.3654870128378791\n",
      "F1: 0.186797605690062\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_google_news_und, X_test_google_news,\n",
    "                    y_train_google_news_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b2338",
   "metadata": {},
   "source": [
    "### 3.1.3 With oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b30e4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Ove'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b69e77",
   "metadata": {},
   "source": [
    "#### Oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cefde8",
   "metadata": {},
   "source": [
    "Again, we used the same oversampling strategy as we used in the notebook 'Vectorization'. We used SMOTE and reduced the imbalance ratio to 4:1 for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d20166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of samples in the majority class\n",
    "ove_n = df_train['category'].value_counts().sort_values(ascending=False)[0]\n",
    "\n",
    "# Oversample until the number of observations equals a fourth of the majority class\n",
    "max_samples = int(ove_n/4)\n",
    "\n",
    "# Dictionary to store the actual maximum imbalance per class for oversampling\n",
    "max_imbalance_o = {}\n",
    "\n",
    "# Calculate the actual maximum imbalance for each class\n",
    "for category in categories:\n",
    "    if category == 'None':\n",
    "        max_imbalance_o[category] = y_train.value_counts()[category]\n",
    "    else:\n",
    "        # Set the actual maximum to the number of available samples\n",
    "        max_imbalance_o[category] = max_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95c47302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SMOTE oversampler\n",
    "oversampler = SMOTE(sampling_strategy=max_imbalance_o, random_state=7)\n",
    "\n",
    "# Undersample the data\n",
    "X_train_google_news_ove, y_train_google_news_ove = oversampler.fit_resample(X_train_google_news, y_train)\n",
    "#y_train_skip_ove.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77534c",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7650ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_log_o'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be1b6b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Results for google_log_o:\n",
      "Accuracy: 0.8451433857539316\n",
      "Precision: 0.31730791885718557\n",
      "Recall: 0.5710006988048183\n",
      "F1: 0.3941828939075108\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_google_news_ove, X_test_google_news,\n",
    "                    y_train_google_news_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b31a10c",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2097986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_DT_o'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f59d7309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1}\n",
      "Results for google_DT_o:\n",
      "Accuracy: 0.7578168362627197\n",
      "Precision: 0.156158291422305\n",
      "Recall: 0.26608290100375365\n",
      "F1: 0.1851608026753601\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_google_news_ove, X_test_google_news,\n",
    "                    y_train_google_news_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e06b9d",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01c45fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_svm_o'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a89c21f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 100, 'kernel': 'rbf'}\n",
      "Results for google_svm_o:\n",
      "Accuracy: 0.9226641998149862\n",
      "Precision: 0.5666147580648718\n",
      "Recall: 0.4113190138393927\n",
      "F1: 0.4708754567420214\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_google_news_ove, X_test_google_news,\n",
    "                    y_train_google_news_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa4fc0",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37bd320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_rf_o'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27481118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 500}\n",
      "Results for google_rf_o:\n",
      "Accuracy: 0.9181313598519889\n",
      "Precision: 0.6295121905159177\n",
      "Recall: 0.3108057864572282\n",
      "F1: 0.38312343531159077\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_google_news_ove, X_test_google_news,\n",
    "                    y_train_google_news_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433c9e51",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "146f47b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_ada_o'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d49b1acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Results for google_ada_w:\n",
      "Accuracy: 0.8988899167437557\n",
      "Precision: 0.3936601818715791\n",
      "Recall: 0.3091661865801134\n",
      "F1: 0.3429136021732111\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_google_news_ove, X_test_google_news,\n",
    "                    y_train_google_news_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269cc479",
   "metadata": {},
   "source": [
    "## 3.2 Glove embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceff8ed",
   "metadata": {},
   "source": [
    "In order to use the Glove embeddings, you first need to download their pretrained vectors on the website below. In our scenario, I used the vectors that were trained based on the Wikipedia 2014 and Gigaword 5. These vectors were trained on 6B tokens and a vocabulary of 400.000 words. It is possible to retrieve embeddins that were trained on a larger dataset. Moreover, these vectors come in 4 dimension. You can choose between 50, 100, 200 or 300 dimensions.\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "58849a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vectorizer method\n",
    "vectorizer = 'pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0408f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define type of pretrained embedding model\n",
    "FS = 'Glove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d243402c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 300)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the formats\n",
    "glove_300_w2v = 'glove.6B.300d.text' + '.w2v'\n",
    "glove2word2vec('/Users/juarel/Desktop/studies artur/thesis_HIR/big files/glove/glove.6B.300d.txt', glove_300_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6bd5adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_300_w2v_model = KeyedVectors.load_word2vec_format(glove_300_w2v, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "19054ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glove_300 = np.vstack([vectorize_pretrained(headline, glove_300_w2v_model, 300) for headline in X_train])\n",
    "X_test_glove_300 = np.vstack([vectorize_pretrained(headline, glove_300_w2v_model, 300) for headline in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e301502e",
   "metadata": {},
   "source": [
    "### 3.2.1 Without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "132171c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a30708",
   "metadata": {},
   "source": [
    "#### A. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6d29259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_log_w'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cc1f37fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Results for glove_log_w:\n",
      "Accuracy: 0.9173913043478261\n",
      "Precision: 0.5497871595562741\n",
      "Recall: 0.36529449119922375\n",
      "F1: 0.4261025509986856\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_glove_300, X_test_glove_300, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8add579d",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e58c49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_DT_w'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f7595175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1}\n",
      "Results for glove_DT_w:\n",
      "Accuracy: 0.8459759481961147\n",
      "Precision: 0.16701373930913935\n",
      "Recall: 0.18357253356327966\n",
      "F1: 0.17404156482711514\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_glove_300, X_test_glove_300, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8a115",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2464491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_svm_w'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d7c0551b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Results for glove_svm_w:\n",
      "Accuracy: 0.925254394079556\n",
      "Precision: 0.6538187560651902\n",
      "Recall: 0.39999421726770995\n",
      "F1: 0.4685016876804864\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_glove_300, X_test_glove_300, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8117314",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68c2a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_rf_w'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "46b52269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "Results for glove_rf_w:\n",
      "Accuracy: 0.9041628122109158\n",
      "Precision: 0.6123548809961117\n",
      "Recall: 0.10631650210077445\n",
      "F1: 0.13385063630938082\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_glove_300, X_test_glove_300, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47509b3",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "06c40b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_ada_w'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c47a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_glove_300, X_test_glove_300, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f633b6",
   "metadata": {},
   "source": [
    "### 3.2.2 With undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3bc6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Und'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22037e06",
   "metadata": {},
   "source": [
    "#### Second strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd23d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data\n",
    "X_train_glove_300_und, y_train_glove_300_und = undersampler.fit_resample(X_train_glove_300, y_train)\n",
    "#y_train_cbow_und.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f12cf",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8857f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_log_u'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea64b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_glove_300_und, X_test_glove_300,\n",
    "                    y_train_glove_300_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaceb393",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516886c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_DT_u'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e5c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_glove_300_und, X_test_glove_300,\n",
    "                    y_train_glove_300_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28460604",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dbaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_svm_u'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c35b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_glove_300_und, X_test_glove_300,\n",
    "                    y_train_glove_300_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fecdae1",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfbf386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_rf_u'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ac23af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_glove_300_und, X_test_glove_300,\n",
    "                    y_train_glove_300_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9990809",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_ada_u'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_glove_300_und, X_test_glove_300,\n",
    "                    y_train_glove_300_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bf41ad",
   "metadata": {},
   "source": [
    "### 3.2.3 With oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Ove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data\n",
    "X_train_glove_300_ove, y_train_glove_300_ove = oversampler.fit_resample(X_train_glove_300, y_train)\n",
    "#y_train_skip_ove.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32fe03e",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca2c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_log_o'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e1a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_glove_300_ove, X_test_glove_300,\n",
    "                    y_train_glove_300_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dceff8",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3377c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_DT_o'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fb9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_glove_300_ove, X_test_glove_300,\n",
    "                    y_train_glove_300_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a883b511",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da40577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_svm_o'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_glove_300_ove, X_test_glove_300,\n",
    "                    y_train_glove_300_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334263df",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_rf_o'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52562ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_glove_300_ove, X_test_glove_300,\n",
    "                    y_train_glove_300_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8feafd3",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9807882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_ada_o'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d118a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_glove_300_ove, X_test_glove_300,\n",
    "                    y_train_glove_300_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9137cf96",
   "metadata": {},
   "source": [
    "## 4. Write away results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write away results\n",
    "results_all_df.to_csv('./Output/Model performance/results_pretrained_embeddings.csv', index = False, header = True)\n",
    "results_all_df.to_excel('./Output/Model performance/results_pretrained_embeddings.xlsx', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dictionary with the best parameters away\n",
    "with open('./Output/parameters/pretrained_embeddings.json', 'w') as file:\n",
    "    json.dump(best_params_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3231e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
