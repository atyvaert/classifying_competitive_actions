{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf43c7f3",
   "metadata": {},
   "source": [
    "# D. Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e5b6d",
   "metadata": {},
   "source": [
    "# 0. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705a75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Packages #\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from scipy.stats import randint\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Sklearn Packages #\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# NLTK Packages #\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Import necessary libraries for handling imbalanced data\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Embedding related imports\n",
    "import sys\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# Transform packages\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import logging\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ac2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn of warnings, just to avoid pesky messages that might cause confusion here\n",
    "# Remove when testing your own code #\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d611c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Headline</th>\n",
       "      <th>category</th>\n",
       "      <th>cleaned_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194578</td>\n",
       "      <td>Head Line: US Patent granted to BASF SE (Delaw...</td>\n",
       "      <td>None</td>\n",
       "      <td>head u patent granted se delaware may titled c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>564295</td>\n",
       "      <td>Societe Generale Launches a Next-Generation Ca...</td>\n",
       "      <td>None</td>\n",
       "      <td>societe generale launch nextgeneration card in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>504138</td>\n",
       "      <td>BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...</td>\n",
       "      <td>None</td>\n",
       "      <td>plc form communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91379</td>\n",
       "      <td>ASML: 4Q Earnings Snapshot</td>\n",
       "      <td>None</td>\n",
       "      <td>4q earnings snapshot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265750</td>\n",
       "      <td>Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...</td>\n",
       "      <td>None</td>\n",
       "      <td>form investment manager group plc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           Headline category  \\\n",
       "0  194578  Head Line: US Patent granted to BASF SE (Delaw...     None   \n",
       "1  564295  Societe Generale Launches a Next-Generation Ca...     None   \n",
       "2  504138  BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...     None   \n",
       "3   91379                         ASML: 4Q Earnings Snapshot     None   \n",
       "4  265750  Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...     None   \n",
       "\n",
       "                                    cleaned_headline  \n",
       "0  head u patent granted se delaware may titled c...  \n",
       "1  societe generale launch nextgeneration card in...  \n",
       "2                             plc form communication  \n",
       "3                               4q earnings snapshot  \n",
       "4                  form investment manager group plc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to Working Directory with Training Data # \n",
    "#os.chdir(\"/Users/Artur/Desktop/thesis_HIR_versie5/coding\")\n",
    "os.chdir(\"/Users/juarel/Desktop/studies artur/thesis_HIR/coding\")\n",
    "\n",
    "# Load the preprocessed data #\n",
    "df_train = pd.read_csv(\"./data/gold_data/train.csv\", header = 0)\n",
    "df_test = pd.read_csv(\"./data/gold_data/test.csv\", header = 0)\n",
    "\n",
    "# inspect the data\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb86cefd",
   "metadata": {},
   "source": [
    "# 1. Define functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccab087",
   "metadata": {},
   "source": [
    "Before we continue, we first define some useful functions and parameters that we use throughout this notebook. The first four functions and parameters were also used and defined in the previous notebook.\n",
    "\n",
    "1. get_classification_metrics: Create a function that return the classification metrics for each model. The precision, recall and f1 score are all determined using the average value of all classes, without adjusting weights to these classes.\n",
    "\n",
    "2. Define a dataframe to store the results of the different models. Moreover, also define a dictionary that stores the best parameters for each model.\n",
    "\n",
    "3. Define the number of splits, the stratified cross validator to ensure class frequencies are considered, and the scoring metric based on the average F1 score. We use an F1 score as scoring metric as accuracy is not a good evaluation metric in our case.\n",
    "\n",
    "4. Define a function that trains the defined model, the input data, the classifier and its parameter grid. Besides, it will also take 4 parameters as input that give more information about the model that is being trained. This is usefull for the storage of the performance of the different algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf61e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Function that returns classication metrics\n",
    "def get_classification_metrics(y_true, y_pred):\n",
    "    \n",
    "    # Calculate Model Performance Metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4703149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create an empty dataframe to store the results of all the models\n",
    "results_all_df = pd.DataFrame()\n",
    "\n",
    "# Add columns for the metrics\n",
    "columns = ['vectorizer', 'FS', 'classifier', 'resampling','accuracy', 'precision', 'recall', 'f1']\n",
    "for col in columns:\n",
    "    results_all_df[col] = 0\n",
    "\n",
    "# create an empty dictionary to store the optimal parameters\n",
    "best_params_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d97903e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define different parameters\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize the stratified k-fold object\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42) # ensures class balances are kept\n",
    "\n",
    "# Define the scoring metric\n",
    "scoring = make_scorer(f1_score, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab6ad650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the independent and dependent variables\n",
    "X_train = df_train['cleaned_headline']\n",
    "X_test = df_test['cleaned_headline']\n",
    "\n",
    "y_train = df_train['category']\n",
    "y_test = df_test['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c12a88",
   "metadata": {},
   "source": [
    "# 2. Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3037b01",
   "metadata": {},
   "source": [
    "https://simpletransformers.ai/docs/classification-specifics/#supported-model-types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b018e",
   "metadata": {},
   "source": [
    "## 2.1 Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dda4e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define with what vectorizer we build the models with for storage\n",
    "vectorizer = 'Transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "607f4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the implementation method of word2vec\n",
    "FS = 'Bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3417a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c7101",
   "metadata": {},
   "source": [
    "By default, ClassificationModel expects the labels to be ints from 0 up to num_labels.\n",
    "\n",
    "If your dataset contains labels in another format (e.g. string labels like positive, negative), you can provide the list of all labels to the model args. Simple Transformers will handle the label mappings internally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d75cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a82e6a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the labels as integers\n",
    "label_encoder = LabelEncoder()\n",
    "df_train[\"label_encoded\"] = label_encoder.fit_transform(df_train[\"category\"])\n",
    "df_test[\"label_encoded\"] = label_encoder.transform(df_test[\"category\"])\n",
    "\n",
    "\n",
    "# Get the number of labels\n",
    "num_labels = len(label_encoder.classes_)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20ef59ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train_df and apply label decoding to obtain string labels\n",
    "input_transf = df_train[['cleaned_headline', 'label_encoded']]\n",
    "input_transf.columns = [\"text\", \"labels\"]\n",
    "input_transf['labels'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75f293d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transf = df_test[['cleaned_headline', 'label_encoded']]\n",
    "test_transf.columns = [\"text\", \"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19ee45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd03ade0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e69be139d934a74a769bd508e60acdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad852f3b74274a7db2605d9a9c19ccc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c04ac55119a4a37b733edf55cc3d2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8babd61e64cb4829b3b950f8d603deb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac9191dad0247d5930e8b8a48e781e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de290c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a475ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 0\n",
    "length = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd923b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each sentence in the cleaned_headline column\n",
    "for sentence in df_train['cleaned_headline']:\n",
    "   # Split the sentence into words\n",
    "   words = sentence.split()\n",
    "   # Update the maximum length if the current sentence is longer\n",
    "   l = len(words)\n",
    "   length.append(l)\n",
    "\n",
    "np.mean(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the 'length' array\n",
    "# Sort the DataFrame by 'Sentence Length' column in descending order\n",
    "df_sorted = df_lengths.sort_values(by='Sentence Length', ascending=False)\n",
    "df_sorted.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44898a2f",
   "metadata": {},
   "source": [
    "https://simpletransformers.ai/docs/usage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a96f73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27327</th>\n",
       "      <td>pfizer germany kgaa say phase gastric cancer t...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21429</th>\n",
       "      <td>group report interim report q2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37790</th>\n",
       "      <td>holding stuart gulliver remuneration last year</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36442</th>\n",
       "      <td>report gross short sale australia</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29039</th>\n",
       "      <td>plc form abbvie plc amendment</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37943</th>\n",
       "      <td>duke energy siemens enter innovative agreement...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19017</th>\n",
       "      <td>standard plc scplc half year result</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>deutsche bank ag form eptri sabmiller plc</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22427</th>\n",
       "      <td>china rare protest citizen oppose deal gmos</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30562</th>\n",
       "      <td>british land co plc transaction share</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34596 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels\n",
       "27327  pfizer germany kgaa say phase gastric cancer t...       9\n",
       "21429                     group report interim report q2       9\n",
       "37790     holding stuart gulliver remuneration last year       9\n",
       "36442                  report gross short sale australia       9\n",
       "29039                      plc form abbvie plc amendment       9\n",
       "...                                                  ...     ...\n",
       "37943  duke energy siemens enter innovative agreement...      13\n",
       "19017                standard plc scplc half year result       9\n",
       "298            deutsche bank ag form eptri sabmiller plc       9\n",
       "22427        china rare protest citizen oppose deal gmos       9\n",
       "30562              british land co plc transaction share       9\n",
       "\n",
       "[34596 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import argv\n",
    "\n",
    "train_df, eval_df = train_test_split(input_transf, test_size=0.2, stratify=input_transf['labels'], random_state=7)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e0c2de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_multiclass(labels, preds):\n",
    "    return f1_score(labels, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea527c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = argv[1]\n",
    "model_name = argv[2]\n",
    "\n",
    "# define path for storage as very large files and can not be pushed in github\n",
    "file_path = '/Users/juarel/Desktop/studies artur/thesis_HIR/big files/'\n",
    "\n",
    "train_args = {\n",
    "    'output_dir': f'{file_path}{model_type}-{model_name}-outputs',\n",
    "    'best_model_dir': f'{file_path}{model_type}-{model_name}-outputs/best_model', # directory to save best models at check points\n",
    "    'cache_dir': f'{file_path}{model_type}-{model_name}-cache_dir',\n",
    "\n",
    "    'max_seq_length': 69,            # maximum number of tokens (= words) per input, only few observations have more than 69 tokens \n",
    "    'do_lower_case': True,           # Set true when using uncased models\n",
    "    'num_train_epochs': 3,           # The number of times the equivalent of a full training set has been processed\n",
    "    'train_batch_size': 32,          # The training batch size\n",
    "    'eval_batch_size': 16,           # The evaluation batch size\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'learning_rate': 4e-5,           # Controls how fast model weights are updated\n",
    "    'save_steps': 1000,\n",
    "    'early_stopping_metric_minimize': True,\n",
    "\n",
    "    #'wandb_kwargs': {'name': f'{model_type}-{model_name}'},\n",
    "    'evaluate_during_training': True,        # Perform evaluation while training the model\n",
    "    'evaluate_during_training_steps': 1000,  # Perfrom evaluation at every specified number of steps\n",
    "    \"save_model_every_epoch\": False,         # Save a model checkpoint at the end of every epoch.\n",
    "    'overwrite_output_dir': True,            # Overwrite existing saved models in same directory\n",
    "    'no_cache': True,                        # No cache features to disk\n",
    "    'use_multiprocessing': True,              # use multiprocessing when converting data into features\n",
    "\n",
    "    'use_early_stopping': True,       # Early stopping technique to prevent overfitting\n",
    "    'early_stopping_patience': 5,     # Terminate if loss does not improve for 5 consecutive evaluations\n",
    "    'early_stopping_delta': 0.01,     # amount the evaluation data needs to improve to be considered better\n",
    "    'manual_seed': 7,                 # Ensure results can be reproduced\n",
    "    'weight_decay': 0.001,             # Adds L2 penalty (low due to limited dataset)\n",
    "    'early_stopping_metric': f1_multiclass\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf9a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c118588819e46b38f3890831e4b05b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34596 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = ClassificationModel('bert', 'bert-base-uncased', num_labels=15, args=train_args, \n",
    "                            use_cuda = False)\n",
    "model.train_model(train_df, eval_df=eval_df, f1 = f1_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb31a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(test_transf,\n",
    "                                                            f1=f1_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c3b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a8979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4203e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e68fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0e58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed8db03c",
   "metadata": {},
   "source": [
    "## 4. Write away results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write away results\n",
    "results_all_df.to_csv('./Output/Model performance/results_transformers.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dictionary with the best parameters away\n",
    "with open('./Output/parameters/embeddings.json', 'w') as file:\n",
    "    json.dump(best_params_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
