{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf43c7f3",
   "metadata": {},
   "source": [
    "# D. Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e5b6d",
   "metadata": {},
   "source": [
    "# 0. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705a75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Packages #\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from scipy.stats import randint\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Sklearn Packages #\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# NLTK Packages #\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Import necessary libraries for handling imbalanced data\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Embedding related imports\n",
    "import sys\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# Transform packages\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import logging\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ac2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn of warnings, just to avoid pesky messages that might cause confusion here\n",
    "# Remove when testing your own code #\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d611c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Headline</th>\n",
       "      <th>category</th>\n",
       "      <th>cleaned_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194578</td>\n",
       "      <td>Head Line: US Patent granted to BASF SE (Delaw...</td>\n",
       "      <td>None</td>\n",
       "      <td>head u patent granted se delaware may titled c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>564295</td>\n",
       "      <td>Societe Generale Launches a Next-Generation Ca...</td>\n",
       "      <td>None</td>\n",
       "      <td>societe generale launch nextgeneration card in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>504138</td>\n",
       "      <td>BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...</td>\n",
       "      <td>None</td>\n",
       "      <td>plc form communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91379</td>\n",
       "      <td>ASML: 4Q Earnings Snapshot</td>\n",
       "      <td>None</td>\n",
       "      <td>4q earnings snapshot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265750</td>\n",
       "      <td>Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...</td>\n",
       "      <td>None</td>\n",
       "      <td>form investment manager group plc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           Headline category  \\\n",
       "0  194578  Head Line: US Patent granted to BASF SE (Delaw...     None   \n",
       "1  564295  Societe Generale Launches a Next-Generation Ca...     None   \n",
       "2  504138  BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...     None   \n",
       "3   91379                         ASML: 4Q Earnings Snapshot     None   \n",
       "4  265750  Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...     None   \n",
       "\n",
       "                                    cleaned_headline  \n",
       "0  head u patent granted se delaware may titled c...  \n",
       "1  societe generale launch nextgeneration card in...  \n",
       "2                             plc form communication  \n",
       "3                               4q earnings snapshot  \n",
       "4                  form investment manager group plc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to Working Directory with Training Data # \n",
    "#os.chdir(\"/Users/Artur/Desktop/thesis_HIR_versie5/coding\")\n",
    "os.chdir(\"/Users/juarel/Desktop/studies artur/thesis_HIR/coding\")\n",
    "\n",
    "# Load the preprocessed data #\n",
    "df_train = pd.read_csv(\"./data/gold_data/train.csv\", header = 0)\n",
    "df_test = pd.read_csv(\"./data/gold_data/test.csv\", header = 0)\n",
    "\n",
    "# inspect the data\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb86cefd",
   "metadata": {},
   "source": [
    "# 1. Define functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccab087",
   "metadata": {},
   "source": [
    "Before we continue, we first define some useful functions and parameters that we use throughout this notebook. The first four functions and parameters were also used and defined in the previous notebook.\n",
    "\n",
    "1. get_classification_metrics: Create a function that return the classification metrics for each model. The precision, recall and f1 score are all determined using the average value of all classes, without adjusting weights to these classes.\n",
    "\n",
    "2. Define a dataframe to store the results of the different models. Moreover, also define a dictionary that stores the best parameters for each model.\n",
    "\n",
    "3. Define the number of splits, the stratified cross validator to ensure class frequencies are considered, and the scoring metric based on the average F1 score. We use an F1 score as scoring metric as accuracy is not a good evaluation metric in our case.\n",
    "\n",
    "4. Define a function that trains the defined model, the input data, the classifier and its parameter grid. Besides, it will also take 4 parameters as input that give more information about the model that is being trained. This is usefull for the storage of the performance of the different algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf61e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Function that returns classication metrics\n",
    "def get_classification_metrics(y_true, y_pred):\n",
    "    \n",
    "    # Calculate Model Performance Metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4703149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create an empty dataframe to store the results of all the models\n",
    "results_all_df = pd.DataFrame()\n",
    "\n",
    "# Add columns for the metrics\n",
    "columns = ['vectorizer', 'FS', 'classifier', 'resampling','accuracy', 'precision', 'recall', 'f1']\n",
    "for col in columns:\n",
    "    results_all_df[col] = 0\n",
    "\n",
    "# create an empty dictionary to store the optimal parameters\n",
    "best_params_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d97903e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define different parameters\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize the stratified k-fold object\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42) # ensures class balances are kept\n",
    "\n",
    "# Define the scoring metric\n",
    "scoring = make_scorer(f1_score, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab34db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define a function to train and evaluate the different models\n",
    "def perform_grid_search(name, model, param_grid, X_train, X_test, y_train, y_test,\n",
    "                       vectorizer, FS, classifier, resampling):\n",
    "    \n",
    "    # Define a seed value\n",
    "    random.seed(7)\n",
    "        \n",
    "    # Perform the grid search using cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=skf, scoring=scoring)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model and its hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Store the best parameters for the current category in the dictionary\n",
    "    best_params_dict[name] = best_params\n",
    "    print(f'best parameters: {best_params}')\n",
    "\n",
    "    # Retrain the best model with the whole training set\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate the probabilities (not for SVM as this is not possible)\n",
    "    if classifier != 'SVM':\n",
    "        y_pred_proba = best_model.predict_proba(X_test)\n",
    "        \n",
    "        # Find the highest probability for each observation\n",
    "        highest_prob = np.amax(y_pred_proba, axis = 1)\n",
    "    \n",
    "        # Create a DataFrame with test observations, highest probabilities, and predicted classes\n",
    "        predictions_df = pd.DataFrame({'Observation_nr': y_test.index, 'Probability': highest_prob, 'Prediction': y_pred})\n",
    "        \n",
    "    else:\n",
    "        # Create a DataFrame with test observations and predicted classes\n",
    "        predictions_df = pd.DataFrame({'Observation_nr': y_test.index, 'Prediction': y_pred})\n",
    "        \n",
    "    # Store the final predictions with its probability for the test set\n",
    "    predictions_df.to_csv(f'./Output/predictions/{name}.csv', index = False, header = True)\n",
    "    #predictions_df.to_excel(f'./Output/predictions/{name}.xlsx', index = False, header = True)\n",
    "\n",
    "    # Calculate the classification metrics\n",
    "    accuracy, precision, recall, f1 = get_classification_metrics(y_test, y_pred)\n",
    "    \n",
    "    # print the results\n",
    "    print(f'Results for {name}:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1: {f1}')\n",
    "    \n",
    "    # add the results to the dataframe with all the results\n",
    "    results_all_df.loc[name] = [vectorizer, FS, classifier, resampling, accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ffaa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define a function to transform the data into embeddings based on a trained model\n",
    "def vectorize_embedding(headline, model, size):\n",
    "    \n",
    "    # Split the headline into individual words\n",
    "    words = headline.split()\n",
    "\n",
    "    # Retrieve word vectors for each word in the headline\n",
    "    words_vecs = [model.wv[word] for word in words if word in model.wv]\n",
    "\n",
    "    # If no word vectors are found (i.e., no matching words in the pretrained model),\n",
    "    # return a zero vector of the defined dimension\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(size)\n",
    "\n",
    "    # Convert the list of word vectors into a numpy array and average across all words\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    mean_vector = words_vecs.mean(axis=0)\n",
    "\n",
    "    return mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df299197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Define a function to transform the data into embeddings based on a pretrained model\n",
    "def vectorize_pretrained(headline, pre_trained_model, size):\n",
    "\n",
    "    # Split the headline into individual words\n",
    "    words = headline.split()\n",
    "\n",
    "    # Retrieve word embedding for each word in the headline\n",
    "    words_vecs = [pre_trained_model[word] for word in words if word in pre_trained_model]\n",
    "\n",
    "    # If no word vectors are found (i.e., no matching words in the pretrained model),\n",
    "    # return a zero vector of the specified dimension\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(size)\n",
    "\n",
    "    # Convert the list of word vectors into a numpy array and average across word vectors\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    mean_vector = words_vecs.mean(axis=0)\n",
    "\n",
    "    return mean_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab6ad650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the independent and dependent variables\n",
    "X_train = df_train['cleaned_headline']\n",
    "X_test = df_test['cleaned_headline']\n",
    "\n",
    "y_train = df_train['category']\n",
    "y_test = df_test['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c12a88",
   "metadata": {},
   "source": [
    "# 2. Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59a2bd",
   "metadata": {},
   "source": [
    "https://simpletransformers.ai/docs/classification-specifics/#supported-model-types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b018e",
   "metadata": {},
   "source": [
    "## 2.1 Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dda4e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define with what vectorizer we build the models with for storage\n",
    "vectorizer = 'Transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "607f4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the implementation method of word2vec\n",
    "FS = 'Bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd68578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a08432",
   "metadata": {},
   "source": [
    "By default, ClassificationModel expects the labels to be ints from 0 up to num_labels.\n",
    "\n",
    "If your dataset contains labels in another format (e.g. string labels like positive, negative), you can provide the list of all labels to the model args. Simple Transformers will handle the label mappings internally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a780c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "116a7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df_train['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79675fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional model configuration\n",
    "model_args = ClassificationArgs()\n",
    "model_args.num_train_epochs= 5\n",
    "model_args.labels_list = [categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "756d07f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the labels as integers\n",
    "label_encoder = LabelEncoder()\n",
    "df_train[\"label_encoded\"] = label_encoder.fit_transform(df_train[\"category\"])\n",
    "\n",
    "# Get the number of labels\n",
    "num_labels = len(label_encoder.classes_)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f2a0f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    \"num_train_epochs\": 10,\n",
    "    \"train_batch_size\": 16,\n",
    "    \"eval_batch_size\": 32,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"save_model_every_epoch\": False,\n",
    "    \"reprocess_input_data\": True,\n",
    "    'do_lower_case':True,\n",
    "    \"num_labels\": num_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f5d982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(\n",
    "    \"roberta\", \"roberta-base\", args=model_args, use_cuda=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9cdb984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train_df and apply label decoding to obtain string labels\n",
    "input_transf = df_train[['cleaned_headline', 'label_encoded']]\n",
    "input_transf.columns = [\"text\", \"labels\"]\n",
    "input_transf['labels'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9473059d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe9916197fd4a298d202da2ef7bedd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403ca9d7b80c4e3a83ad28655a2b70bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a570a90d044c6ca303066383be4404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/5406 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional model configuration\n",
    "model_args = ClassificationArgs(num_train_epochs=1)\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(\n",
    "    'bert',\n",
    "    'bert-base-cased',\n",
    "    num_labels=15,\n",
    "    args=model_args,\n",
    "    use_cuda = False) \n",
    "\n",
    "# Train the model\n",
    "model.train_model(input_transf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3544e1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727169df07964edbbf5e9d3041ef9fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92903f4b8ccf497f94f8f7a40010b36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92447c5dafc34f5fb7b35d0a6c08731f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 10:   0%|          | 0/2703 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "Target 9 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-caf5ca4229ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model using train_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_transf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         global_step, training_details = self.train(\n\u001b[0m\u001b[1;32m    633\u001b[0m             \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataloader, output_dir, multi_label, show_running_loss, eval_df, test_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m                         )\n\u001b[1;32m    915\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m                     loss, *_ = self._calculate_loss(\n\u001b[0m\u001b[1;32m    917\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m                         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36m_calculate_loss\u001b[0;34m(self, model, inputs, loss_fct, num_labels, args)\u001b[0m\n\u001b[1;32m   2324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m         \u001b[0;31m# model outputs are always tuple in pytorch-transformers (see doc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"single_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 9 is out of bounds."
     ]
    }
   ],
   "source": [
    "# Train the model using train_df\n",
    "model.train_model(input_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96834996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set and decode the integer labels to obtain string labels\n",
    "_, predictions = model.predict([text for text, _ in TestDataframe])\n",
    "predicted_labels = label_encoder.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967a84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data\n",
    "test_data = pd.DataFrame({\"text\": X_test})\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions, _ = model.predict(test_data[\"text\"])\n",
    "\n",
    "# Decode the integer predictions back to their original string labels\n",
    "decoded_predictions = label_encoder.inverse_transform(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c71c58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56a70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2171accd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f2610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af257d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803828a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f1693f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9fe5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c662a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8039f3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e69be139d934a74a769bd508e60acdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad852f3b74274a7db2605d9a9c19ccc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c04ac55119a4a37b733edf55cc3d2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8babd61e64cb4829b3b950f8d603deb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac9191dad0247d5930e8b8a48e781e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31fb53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize your text data\n",
    "text = \"This is an example sentence.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Pass the tokenized inputs through the model\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Get the logits (predictions) from the model's output\n",
    "logits = outputs.logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f758dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   0,  713,   16,   41, 1246, 3645,    4,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "713dbeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingDataframe = list(zip( list(X_train), list(y_train)))\n",
    "TestDataframe = list(zip( list(X_test), list(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e361b035",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'N'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-227e9d27d54f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingDataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-227e9d27d54f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingDataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'N'"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(TrainingDataframe)\n",
    "train_df.columns = [\"text\", \"labels\"]\n",
    "#train_df[\"label\"] = train_df[\"label\"].apply(lambda x: list(map(int, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59766b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95d4a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a3825f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d95294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f1e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8435c17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7bb63da",
   "metadata": {},
   "source": [
    "### 2.1.1 Without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a7f0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c32853",
   "metadata": {},
   "source": [
    "#### A. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feb03e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_log_w'\n",
    "classifier = 'logR'\n",
    "\n",
    "# Initialize the classifier\n",
    "logreg = LogisticRegression(random_state = 7)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_log = {\n",
    "    'penalty': ['None', 'l2'], # normal or ridge regression\n",
    "    'C': [0.1, 1, 10]          # The inverse penalization term (smaller is higher penalization)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0bc2428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Results for cbow_log_w:\n",
      "Accuracy: 0.9148011100832563\n",
      "Precision: 0.48967905538511797\n",
      "Recall: 0.3354442829833037\n",
      "F1: 0.39040754592519994\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_cbow, X_test_cbow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb18666",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6b663d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_DT_w'\n",
    "classifier = 'DT'\n",
    "\n",
    "# Initialize the classifier\n",
    "tree = DecisionTreeClassifier(random_state = 7)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_DT = {\n",
    "    'criterion': ['gini'],          # Define the splitting criteria: Gini index for node impurity\n",
    "    'min_samples_leaf': [1, 2],     # Define the minimum number of samples required to be at leaf node\n",
    "    'max_features': [None, 'sqrt']  # Define the number of features to consider when looking for the best split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e38d4198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1}\n",
      "Results for cbow_DT_w:\n",
      "Accuracy: 0.8632328463103385\n",
      "Precision: 0.22000515730664244\n",
      "Recall: 0.2291982476151896\n",
      "F1: 0.22370150639969272\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_cbow, X_test_cbow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87582e6",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ba127b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_svm_w'\n",
    "classifier = 'SVM'\n",
    "\n",
    "# Initialize the classifier\n",
    "svm = SVC(random_state = 7)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100], # inverse regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf'], # what type of kernel need to be used (rbf = radial kernel)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "47a7dca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 100, 'kernel': 'rbf'}\n",
      "Results for cbow_svm_w:\n",
      "Accuracy: 0.9107638246717218\n",
      "Precision: 0.4642520570714127\n",
      "Recall: 0.34885371463321097\n",
      "F1: 0.3932336178387882\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_cbow, X_test_cbow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d27ae5",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "aa3955b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_rf_w'\n",
    "classifier = 'RF'\n",
    "\n",
    "# Initialize the classifier\n",
    "rfc = RandomForestClassifier(random_state = 7, n_jobs = -1)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'criterion': ['gini'],          # Define the splitting criteria: Gini index for node impurity\n",
    "    'n_estimators': [100, 500],     # the number of trees to use when building the model\n",
    "    'min_samples_leaf': [1, 2],     # Define the minimum number of samples required to be at leaf node\n",
    "    'max_features': [None, 'sqrt']  # Define the number of features to consider when looking for the best split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "14eac49a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-c9fd8dd194c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# perform a grid search for the logistic regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# the results are automatically stored in results_all_df and best_params_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m perform_grid_search(model_name, rfc, param_grid_rf, X_train_cbow, X_test_cbow, y_train, y_test,\n\u001b[0m\u001b[1;32m      4\u001b[0m                    vectorizer, FS, classifier, resampling)\n",
      "\u001b[0;32m<ipython-input-93-597a598ecee4>\u001b[0m in \u001b[0;36mperform_grid_search\u001b[0;34m(name, model, param_grid, X_train, X_test, y_train, y_test, vectorizer, FS, classifier, resampling)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Perform the grid search using cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Get the best model and its hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_cbow, X_test_cbow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5bd69e",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9de3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_ada_w'\n",
    "classifier = 'ADA'\n",
    "\n",
    "# Initialize decision tree base estimator for AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(random_state = 7)\n",
    "\n",
    "# Initialize AdaBoost classifier\n",
    "ada = AdaBoostClassifier(base_estimator = base_estimator, random_state = 7)\n",
    "\n",
    "# Define parameter grid for AdaBoost\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [50, 100, 250],   # the maximum number of estimators before boosting is terminated\n",
    "    'learning_rate': [0.1, 0.5, 1.0], # weight applied to each classifier at boosting iteration\n",
    "                                      # A higher learning rate increases the contribution of each classifier. \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_cbow, X_test_cbow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40b2e5",
   "metadata": {},
   "source": [
    "### 2.1.2 With undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Und'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categories and the maximum number of samples\n",
    "categories = df_train[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81489ad4",
   "metadata": {},
   "source": [
    "#### Random undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317855e3",
   "metadata": {},
   "source": [
    "Again, we used the same undersampling strategy as we used in the notebook 'Vectorization'. We used random undersampling and reduced the imbalance ratio to 4:1 for each category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dc2794",
   "metadata": {},
   "source": [
    "#### Second strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f8b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of samples in the biggest minority category\n",
    "rus_n = df_train['category'].value_counts().sort_values(ascending=False)[1]\n",
    "\n",
    "# Dictionary to store the actual maximum imbalance per class for undersampling\n",
    "max_imbalance_u = {}\n",
    "\n",
    "# Calculate the actual maximum imbalance for each class\n",
    "for category in categories:\n",
    "    if category == 'None':\n",
    "        max_imbalance_u[category] = rus_n\n",
    "    else:\n",
    "        # Set the actual maximum to the number of available samples\n",
    "        max_imbalance_u[category] = y_train.value_counts()[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c83283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random undersampler with maximum imbalance\n",
    "undersampler = RandomUnderSampler(sampling_strategy = max_imbalance_u, random_state = 7)\n",
    "\n",
    "# Undersample the data\n",
    "X_train_cbow_und, y_train_cbow_und = undersampler.fit_resample(X_train_cbow, y_train)\n",
    "#y_train_cbow_und.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd752072",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c39c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_log_u'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_cbow_und, X_test_cbow, y_train_cbow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77751dd0",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294863fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_DT_u'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c34879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_cbow_und, X_test_cbow, y_train_cbow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb224122",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50569b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_svm_u'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_cbow_und, X_test_cbow, y_train_cbow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8cd8d6",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada17123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_rf_u'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e835e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_cbow_und, X_test_cbow, y_train_cbow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c76cc2",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef66e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_ada_u'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0214c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_cbow_und, X_test_cbow, y_train_cbow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc769c64",
   "metadata": {},
   "source": [
    "### 2.1.3 With oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dafedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Ove'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df08c82",
   "metadata": {},
   "source": [
    "#### Oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e22ebc",
   "metadata": {},
   "source": [
    "Again, we used the same oversampling strategy as we used in the notebook 'Vectorization'. We used SMOTE and reduced the imbalance ratio to 4:1 for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab748192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of samples in the majority class\n",
    "ove_n = df_train['category'].value_counts().sort_values(ascending=False)[0]\n",
    "\n",
    "# Oversample until the number of observations equals a fourth of the majority class\n",
    "max_samples = int(ove_n/4)\n",
    "\n",
    "# Dictionary to store the actual maximum imbalance per class for oversampling\n",
    "max_imbalance_o = {}\n",
    "\n",
    "# Calculate the actual maximum imbalance for each class\n",
    "for category in categories:\n",
    "    if category == 'None':\n",
    "        max_imbalance_o[category] = y_train.value_counts()[category]\n",
    "    else:\n",
    "        # Set the actual maximum to the number of available samples\n",
    "        max_imbalance_o[category] = max_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c54e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SMOTE oversampler\n",
    "oversampler = SMOTE(sampling_strategy=max_imbalance_o, random_state=7)\n",
    "\n",
    "# Undersample the data\n",
    "X_train_cbow_ove, y_train_cbow_ove = oversampler.fit_resample(X_train_cbow, y_train)\n",
    "y_train_cbow_ove.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3e0aa",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e731af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_log_o'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d307746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_cbow_ove, X_test_cbow, y_train_cbow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b41767",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08c63da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_DT_o'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42368b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_cbow_ove, X_test_cbow, y_train_cbow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb2138",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9fadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_svm_o'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46798c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_cbow_ove, X_test_cbow, y_train_cbow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e739f4",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_rf_o'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df561e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_cbow_ove, X_test_cbow, y_train_cbow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1015a",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba687ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'cbow_ada_o'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78eb5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_cbow_ove, X_test_cbow, y_train_cbow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbddde1",
   "metadata": {},
   "source": [
    "## 2.2 Create word embeddings with Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e366467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the implementation method of word2vec\n",
    "FS = 'skip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b4f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimension of the vector\n",
    "size = 300\n",
    "\n",
    "# define the cbow_model and train on training set headlines\n",
    "skip_model = Word2Vec(headlines_train, \n",
    "                 min_count = 2,          # Ignore words that appear less than this\n",
    "                 vector_size = size,      # Dimensionality of word embeddings\n",
    "                 workers = 8,            # Number of processors (parallelisation)\n",
    "                 window = 5,             # Context window for words during training\n",
    "                 epochs = 20,            # Number of epochs training over corpus\n",
    "                 sg = 1)                 # 0 for CBOW and 1 for skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a803622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the independent variable of the train and the test set\n",
    "X_train_skip = np.array([vectorize_embedding(headline, skip_model, size) for headline in X_train])\n",
    "X_test_skip = np.array([vectorize_embedding(headline, skip_model, size) for headline in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82157e11",
   "metadata": {},
   "source": [
    "### 2.2.1 Without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38757f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377a5df",
   "metadata": {},
   "source": [
    "#### A. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_log_w'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db34ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_skip, X_test_skip, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b1fa5",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f7888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_DT_w'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd267db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_skip, X_test_skip, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0584b692",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ef1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_svm_w'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8add2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_skip, X_test_skip, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4882f859",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f0a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_rf_w'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_skip, X_test_skip, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcafa60",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d605285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_ada_w'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59028886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_skip, X_test_skip, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d4109d",
   "metadata": {},
   "source": [
    "### 2.1.2 With undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Und'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def53ffe",
   "metadata": {},
   "source": [
    "#### Second strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abace06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data\n",
    "X_train_skip_und, y_train_skip_und = undersampler.fit_resample(X_train_skip, y_train)\n",
    "#y_train_cbow_und.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e6438b",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_log_u'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_skip_und, X_test_skip, y_train_skip_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98238e53",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_DT_u'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_skip_und, X_test_skip, y_train_skip_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1189ac57",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_svm_u'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_skip_und, X_test_skip, y_train_skip_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c661bede",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5178cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_rf_u'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e342634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_skip_und, X_test_skip, y_train_skip_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72558681",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af83e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_ada_u'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_skip_und, X_test_skip, y_train_skip_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86df289",
   "metadata": {},
   "source": [
    "### 2.1.3 With oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b5d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Ove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3d74b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data\n",
    "X_train_skip_ove, y_train_skip_ove = oversampler.fit_resample(X_train_skip, y_train)\n",
    "#y_train_skip_ove.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35594c82",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe347cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_log_o'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96249416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_skip_ove, X_test_skip, y_train_skip_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff4d1f",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b156aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_DT_o'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35cbd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_skip_ove, X_test_skip, y_train_skip_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d98f52",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ebbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_svm_o'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc27e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_skip_ove, X_test_skip, y_train_skip_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b51615",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6216b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_rf_o'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f6b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_skip_ove, X_test_skip, y_train_skip_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ddb647",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fdb244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'skip_ada_o'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f16679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_skip_ove, X_test_skip, y_train_skip_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b3148",
   "metadata": {},
   "source": [
    "#### Intermediate: write the data away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46269f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write away results\n",
    "results_all_df.to_csv('./Output/Model performance/results_embeddings.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dictionary with the best parameters away\n",
    "with open('./Output/parameters/embeddings.json', 'w') as file:\n",
    "    json.dump(best_params_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f222d5",
   "metadata": {},
   "source": [
    "## 3. Pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a63a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vectorizer method\n",
    "vectorizer = 'pretrained'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9af000",
   "metadata": {},
   "source": [
    "### 3.1 Google news embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2a86bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define type of pretrained embedding model\n",
    "FS = 'google news'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18532cc4",
   "metadata": {},
   "source": [
    "Uses continious skipgram: http://vectors.nlpl.eu/repository/?ref=blog.paperspace.com\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/03/pretrained-word-embeddings-nlp/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "122e44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if downloaded offline\n",
    "google_news = KeyedVectors.load_word2vec_format('/Users/Artur/Desktop/thesis_HIR_versie5/big files/google/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62d9e667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 98.1% 1631.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# Download the \"word2vec-google-news-300\" embeddings if not downloaded ofline\n",
    "#google_news = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c536d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings of the train and test set based on the pretrained google_news model\n",
    "X_train_google_news = np.vstack([vectorize_pretrained(headline, google_news, 300) for headline in X_train])\n",
    "X_test_google_news = np.vstack([vectorize_pretrained(headline, google_news, 300) for headline in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0ad320",
   "metadata": {},
   "source": [
    "### 3.1.1 Without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5c653c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cd2ef9",
   "metadata": {},
   "source": [
    "#### A. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406102c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_log_w'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806626e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_google_news, X_test_google_news, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd72fe4",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_DT_w'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_google_news, X_test_google_news, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9df38",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa7df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_svm_w'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_google_news, X_test_google_news, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6b6c9",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9df9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_rf_w'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a6e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_google_news, X_test_google_news, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd16f14",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_ada_w'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ec368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_google_news, X_test_google_news, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be21bc",
   "metadata": {},
   "source": [
    "### 3.1.2 With undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Und'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9428c36c",
   "metadata": {},
   "source": [
    "#### Second strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data\n",
    "X_train_google_news_und, y_train_google_news_und = undersampler.fit_resample(X_train_google_news, y_train)\n",
    "#y_train_cbow_und.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad9fea",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cb566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_log_u'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95558221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_google_news_und, X_test_google_news,\n",
    "                    y_train_google_news_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e66e5",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e514d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_DT_u'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f75029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_google_news_und, X_test_google_news,\n",
    "                    y_train_google_news_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b27818",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067a8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_svm_u'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_google_news_und, X_test_google_news,\n",
    "                    y_train_google_news_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20cf92b",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa72444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_rf_u'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_google_news_und, X_test_google_news,\n",
    "                    y_train_google_news_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41631fd",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_ada_u'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c540522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_google_news_und, X_test_google_news,\n",
    "                    y_train_google_news_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b2338",
   "metadata": {},
   "source": [
    "### 3.1.3 With oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Ove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3481f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data\n",
    "X_train_google_news_ove, y_train_google_news_ove = oversampler.fit_resample(X_train_google_news, y_train)\n",
    "#y_train_skip_ove.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77534c",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7650ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_log_o'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_google_news_ove, X_test_google_news,\n",
    "                    y_train_google_news_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b31a10c",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_DT_o'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d7309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_google_news_ove, X_test_google_news,\n",
    "                    y_train_google_news_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e06b9d",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c45fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_svm_o'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_google_news_ove, X_test_google_news,\n",
    "                    y_train_google_news_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa4fc0",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_rf_o'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27481118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_google_news_ove, X_test_google_news,\n",
    "                    y_train_google_news_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433c9e51",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f47b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_ada_o'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f767921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_google_news_ove, X_test_google_news,\n",
    "                    y_train_google_news_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269cc479",
   "metadata": {},
   "source": [
    "## 3.2 Glove embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525df819",
   "metadata": {},
   "source": [
    "In order to use the Glove embeddings, you first need to download their pretrained vectors on the website below. In our scenario, I used the vectors that were trained based on the Wikipedia 2014 and Gigaword 5. These vectors were trained on 6B tokens and a vocabulary of 400.000 words. It is possible to retrieve embeddins that were trained on a larger dataset. Moreover, these vectors come in 4 dimension. You can choose between 50, 100, 200 or 300 dimensions.\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d045cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vectorizer method\n",
    "vectorizer = 'pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dea6a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define type of pretrained embedding model\n",
    "FS = 'Glove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "728f5937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 300)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the formats\n",
    "glove_300_w2v = 'glove.6B.300d.text' + '.w2v'\n",
    "glove2word2vec('/Users/juarel/Desktop/studies artur/thesis_HIR/big files/glove/glove.6B.300d.txt', glove_300_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e171db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_300_w2v_model = KeyedVectors.load_word2vec_format(glove_300_w2v, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b36d6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glove_300 = np.vstack([vectorize_pretrained(headline, glove_300_w2v_model, 300) for headline in X_train])\n",
    "X_test_glove_300 = np.vstack([vectorize_pretrained(headline, glove_300_w2v_model, 300) for headline in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d78eaf9",
   "metadata": {},
   "source": [
    "### 3.2.1 Without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0b4e416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419af0a",
   "metadata": {},
   "source": [
    "#### A. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f416c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_log_w'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668178ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_glove_300, X_test_glove_300, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ac908",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d47e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_DT_w'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_glove_300, X_test_glove_300, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f74d2",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5411ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_svm_w'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_glove_300, X_test_glove_300, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e6333",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_rf_w'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65044585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_glove_300, X_test_glove_300, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952932c0",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f6396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_ada_w'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_glove_300, X_test_glove_300, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd72c2c",
   "metadata": {},
   "source": [
    "### 3.2.2 With undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412da1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Und'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ceea4",
   "metadata": {},
   "source": [
    "#### Second strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data\n",
    "X_train_glove_300_und, y_train_glove_300_und = undersampler.fit_resample(X_train_glove_300, y_train)\n",
    "#y_train_cbow_und.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d8959",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0574a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_log_u'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b035a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_glove_300_und, X_test_glove_300,\n",
    "                    y_train_glove_300_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb59f38",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_DT_u'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b754a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_glove_300_und, X_test_glove_300,\n",
    "                    y_train_glove_300_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacda6c3",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_svm_u'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d6795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_glove_300_und, X_test_glove_300,\n",
    "                    y_train_glove_300_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c2b5db",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f2ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_rf_u'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53214e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_glove_300_und, X_test_glove_300,\n",
    "                    y_train_glove_300_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fbaa05",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ddc985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_ada_u'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6114de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_glove_300_und, X_test_glove_300,\n",
    "                    y_train_glove_300_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c308e9",
   "metadata": {},
   "source": [
    "### 3.2.3 With oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Ove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data\n",
    "X_train_glove_300_ove, y_train_glove_300_ove = oversampler.fit_resample(X_train_glove_300, y_train)\n",
    "#y_train_skip_ove.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44551fdf",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_log_o'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6650f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_glove_300_ove, X_test_glove_300,\n",
    "                    y_train_glove_300_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d375b59c",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_DT_o'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9605bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_glove_300_ove, X_test_glove_300,\n",
    "                    y_train_glove_300_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2e9f1e",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83430488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_svm_o'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21301891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_glove_300_ove, X_test_glove_300,\n",
    "                    y_train_glove_300_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd676d85",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d972f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_rf_o'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_glove_300_ove, X_test_glove_300,\n",
    "                    y_train_glove_300_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f2f596",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'glove_ada_o'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e68056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_glove_300_ove, X_test_glove_300,\n",
    "                    y_train_glove_300_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc160da",
   "metadata": {},
   "source": [
    "## 3.3 Spacy model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9791bd",
   "metadata": {},
   "source": [
    "https://spacy.io/models/en#en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8f7a9d",
   "metadata": {},
   "source": [
    "One of the shortcomings of the two previous pretrained models is that they are trained on data from 2013 (google news dataset) and 2014 (Glove embeddings). However, our data consists out headlines that were published between 2014 and 2020. Therefore, we also aimed to use a pretrained model based on more recent data. Therefore, we use the Spacy package. Spacy is a powerful natural language package that has four basic pipeline models to convert English words from text to embeddings:\n",
    "\n",
    "1. en_core_web_sm\n",
    "2. en_core_web_md\n",
    "3. en_core_web_lg\n",
    "4. en_core_web_trf\n",
    "\n",
    "The sm (small), md (medium) and lg (large) models are all designed to run on a CPU (regular computer). The trf is transformer based (Roberta Model) and runs best on a GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "809249a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "# In case it's not already downloaded, then run this code to download it # \n",
    "#import spacy.cli\n",
    "#spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42cc40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NLP Model from Spacy #\n",
    "spacy_lg = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "421a54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_spacy_lg = np.vstack([spacy_lg(headline).vector.reshape(1,-1) for headline in X_train])\n",
    "X_test_spacy_lg = np.vstack([spacy_lg(headline).vector.reshape(1,-1) for headline in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7446650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vectorizer method\n",
    "vectorizer = 'pretrained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "07bed20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define type of pretrained embedding model\n",
    "FS = 'Spacy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e34f725",
   "metadata": {},
   "source": [
    "### 3.3.1 Without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8caee020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04267ed",
   "metadata": {},
   "source": [
    "#### A. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0571bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_log_w'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63404acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_spacy_lg, X_test_spacy_lg, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b935be6",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_DT_w'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_spacy_lg, X_test_spacy_lg, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cb6c53",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533941e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_svm_w'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_spacy_lg, X_test_spacy_lg, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07444e",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5695c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_rf_w'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59254968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_spacy_lg, X_test_spacy_lg, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056f236c",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebeb7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_ada_w'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26713fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_spacy_lg, X_test_spacy_lg, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e44681",
   "metadata": {},
   "source": [
    "### 3.3.2 With undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eea21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Und'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ead4df",
   "metadata": {},
   "source": [
    "#### Second strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data\n",
    "X_train_spacy_und, y_train_spacy_und = undersampler.fit_resample(X_train_spacy_lg, y_train)\n",
    "#y_train_cbow_und.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b00a3e3",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34aa424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_log_u'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d39bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_spacy_und, X_test_spacy_lg,\n",
    "                    y_train_spacy_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0f2f5a",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7370bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_DT_u'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce72d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_spacy_und, X_test_spacy_lg,\n",
    "                    y_train_spacy_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f33d4e",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e229ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_svm_u'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_spacy_und, X_test_spacy_lg,\n",
    "                    y_train_spacy_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841e75d8",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_rf_u'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_spacy_und, X_test_spacy_lg,\n",
    "                    y_train_spacy_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedd4ff6",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc4e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_ada_u'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_spacy_und, X_test_spacy_lg,\n",
    "                    y_train_spacy_und, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b24ba3",
   "metadata": {},
   "source": [
    "### 3.3.3 With oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2300168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Ove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9317a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the data\n",
    "X_train_spacy_ove, y_train_spacy_ove = oversampler.fit_resample(X_train_spacy_lg, y_train)\n",
    "#y_train_skip_ove.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e429cd",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fac039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_log_o'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d1366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_spacy_ove, X_test_spacy_lg,\n",
    "                    y_train_spacy_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb43da7",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963cafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_DT_o'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68335116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_spacy_ove, X_test_spacy_lg,\n",
    "                    y_train_spacy_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2bd9e6",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475dea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'google_svm_o'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf0343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_google_news_ove, X_test_google_news,\n",
    "                    y_train_google_news_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24bb386",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a842207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_rf_o'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ed403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_spacy_ove, X_test_spacy_lg,\n",
    "                    y_train_spacy_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4af538",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63254af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'spacy_ada_o'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8499086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_spacy_ove, X_test_spacy_lg,\n",
    "                    y_train_spacy_ove, y_test, vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8db03c",
   "metadata": {},
   "source": [
    "## 4. Write away results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a345ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write away results\n",
    "results_all_df.to_csv('./Output/Model performance/results_embeddings.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dictionary with the best parameters away\n",
    "with open('./Output/parameters/embeddings.json', 'w') as file:\n",
    "    json.dump(best_params_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
