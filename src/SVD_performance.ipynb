{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf43c7f3",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e5b6d",
   "metadata": {},
   "source": [
    "# 0. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705a75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Packages #\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from scipy.stats import randint\n",
    "import random\n",
    "\n",
    "\n",
    "# Load TQDM to Show Progress Bars #\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "\n",
    "# Sklearn Packages #\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# NLTK Packages #\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "# for SVD\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3216d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off warnings, just to avoid pesky messages that might cause confusion here\n",
    "# Remove when testing your own code #\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d611c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Headline</th>\n",
       "      <th>category</th>\n",
       "      <th>cleaned_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194578</td>\n",
       "      <td>Head Line: US Patent granted to BASF SE (Delaw...</td>\n",
       "      <td>None</td>\n",
       "      <td>head u patent granted se delaware may titled c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>564295</td>\n",
       "      <td>Societe Generale Launches a Next-Generation Ca...</td>\n",
       "      <td>None</td>\n",
       "      <td>societe generale launch nextgeneration card in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>504138</td>\n",
       "      <td>BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...</td>\n",
       "      <td>None</td>\n",
       "      <td>plc form communication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91379</td>\n",
       "      <td>ASML: 4Q Earnings Snapshot</td>\n",
       "      <td>None</td>\n",
       "      <td>4q earnings snapshot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265750</td>\n",
       "      <td>Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...</td>\n",
       "      <td>None</td>\n",
       "      <td>form investment manager group plc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           Headline category  \\\n",
       "0  194578  Head Line: US Patent granted to BASF SE (Delaw...     None   \n",
       "1  564295  Societe Generale Launches a Next-Generation Ca...     None   \n",
       "2  504138  BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...     None   \n",
       "3   91379                         ASML: 4Q Earnings Snapshot     None   \n",
       "4  265750  Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...     None   \n",
       "\n",
       "                                    cleaned_headline  \n",
       "0  head u patent granted se delaware may titled c...  \n",
       "1  societe generale launch nextgeneration card in...  \n",
       "2                             plc form communication  \n",
       "3                               4q earnings snapshot  \n",
       "4                  form investment manager group plc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to Working Directory with Training Data # \n",
    "#os.chdir(\"/Users/Artur/Desktop/thesis_HIR_versie5/coding\")\n",
    "os.chdir(\"/Users/juarel/Desktop/studies artur/thesis_HIR/coding\")\n",
    "\n",
    "# Load Training Data #\n",
    "df_train = pd.read_csv(\"./data/gold_data/train.csv\", header = 0)\n",
    "df_test = pd.read_csv(\"./data/gold_data/test.csv\", header = 0)\n",
    "\n",
    "# inspect the data\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2d651",
   "metadata": {},
   "source": [
    "# 1. Define functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccab087",
   "metadata": {},
   "source": [
    "Before we continue, we first define some useful functions and parameters that we will need later in this notebook:\n",
    "\n",
    "1. get_classification_metrics: Create a function that return the classification metrics for each model. The precision, recall and f1 score are all determined using the average value of all classes, without adjusting weights to these classes.\n",
    "\n",
    "2. Define a dataframe to store the results of training the optimal model with a different number of features.\n",
    "\n",
    "3. Define a dataframe that stores the results of the models trained with singular value decomposition.\n",
    "\n",
    "4. Define the number of splits, the stratified cross validator to ensure class frequencies are considered, and the scoring metric.\n",
    "\n",
    "5. Define a function that trains the defined model, depending on the vectorizer, the input data, the classifier and its parameter grid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf61e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Function that returns classication metrics\n",
    "def get_classification_metrics(y_true, y_pred):\n",
    "    # Calculate Model Performance Metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4703149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe to store the results of all the models\n",
    "results_log_df = pd.DataFrame()\n",
    "\n",
    "# Add columns for the metrics\n",
    "columns = ['features', 'performance']\n",
    "for col in columns:\n",
    "    results_log_df[col] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083aee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store the results of different max features in vectorizer\n",
    "results_vec_df = pd.DataFrame()\n",
    "\n",
    "# Add columns for the metrics\n",
    "columns = ['vectorizer', 'FS', 'classifier', 'resampling', 'max_features', 'accuracy', 'precision', 'recall', 'f1']\n",
    "for col in columns:\n",
    "    results_vec_df[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97903e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize the stratified k-fold object\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42) # ensures class balances are kept\n",
    "\n",
    "# Define the scoring metric\n",
    "scoring = make_scorer(f1_score, average= 'macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce7f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the independent and dependent variables\n",
    "X_train = df_train['cleaned_headline']\n",
    "X_test = df_test['cleaned_headline']\n",
    "\n",
    "y_train = df_train['category']\n",
    "y_test = df_test['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0615a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dictionary to store the optimal parameters\n",
    "best_params_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab34db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(name, model, param_grid, X_train, X_test, y_train, y_test,\n",
    "                       vectorizer, FS, classifier, resampling, max_features):\n",
    "    \n",
    "    # Define a seed value\n",
    "    random.seed(7)\n",
    "        \n",
    "    # Perform the grid search using cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=skf, scoring=scoring)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model and its hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Store the best parameters for the current category in the dictionary\n",
    "    best_params_dict[name] = best_params\n",
    "    #print(f'best parameters: {best_params}')\n",
    "\n",
    "    # Retrain the best model with the whole training set\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate the probabilities (not for SVM as this is not possible)\n",
    "    if classifier != 'SVM':\n",
    "        y_pred_proba = best_model.predict_proba(X_test)\n",
    "        \n",
    "        # Find the highest probability for each observation\n",
    "        highest_prob = np.amax(y_pred_proba, axis = 1)\n",
    "    \n",
    "        # Create a DataFrame with test observations, highest probabilities, and predicted classes\n",
    "        predictions_df = pd.DataFrame({'Observation_nr': y_test.index, 'Probability': highest_prob, 'Prediction': y_pred})\n",
    "        \n",
    "    else:\n",
    "        # Create a DataFrame with test observations and predicted classes\n",
    "        predictions_df = pd.DataFrame({'Observation_nr': y_test.index, 'Prediction': y_pred})\n",
    "        \n",
    "    # Store the final predictions with its probability for the test set\n",
    "    predictions_df.to_csv(f'./Output/predictions/{name}.csv', index = False, header = True)\n",
    "    #predictions_df.to_excel(f'./Output/predictions/{name}.xlsx', index = False, header = True)\n",
    "\n",
    "    # Calculate the classification metrics\n",
    "    accuracy, precision, recall, f1 = get_classification_metrics(y_test, y_pred)\n",
    "    \n",
    "    # print the results\n",
    "    #print(f'Results for {name}:')\n",
    "    #print(f'Accuracy: {accuracy}')\n",
    "    #print(f'Precision: {precision}')\n",
    "    #print(f'Recall: {recall}')\n",
    "    print(f'F1: {f1}')\n",
    "    \n",
    "    # add the results to the dataframe with the results for different max_features\n",
    "    results_vec_df.loc[name] = [vectorizer, FS, classifier, resampling, max_features, accuracy, precision, recall, f1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c12a88",
   "metadata": {},
   "source": [
    "# 2. Vectorizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc61da4",
   "metadata": {},
   "source": [
    "## 2.1 Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d50f03",
   "metadata": {},
   "source": [
    "Define the parameters of the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04cbfa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Document Frequency -- Maximum share of documents where a word needs to occur to be considered #\n",
    "MAXDF = 0.9\n",
    "\n",
    "# Maximum number of features we would want to consider -- ranked by most frequently occuring #\n",
    "MF= 10000\n",
    "\n",
    "# NGrams -- Number of Word Pairs. Takes the form (Min, Max). E.g. (1, 2) means single words and word pairs # \n",
    "NGrams = (1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab74ed0",
   "metadata": {},
   "source": [
    "Define the vectorizer itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "454fb3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the vectorizer\n",
    "vec_bow = CountVectorizer(max_features= MF,\n",
    "                          max_df = MAXDF,\n",
    "                          ngram_range=NGrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9b08a",
   "metadata": {},
   "source": [
    "Transform the textual data into numerical representations with the BOW vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3da4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier\n",
    "logreg = LogisticRegression(random_state = 7, penalty = 'l2', C = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0b6b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each value of 'i'\n",
    "for i in range(2000, 20001, 500):\n",
    "    \n",
    "    # Train your logistic regression model with the current 'i'\n",
    "    model = logreg\n",
    "    \n",
    "    # define the vectorizer\n",
    "    vec_bow = CountVectorizer(max_features= i,\n",
    "                          max_df = MAXDF,\n",
    "                          ngram_range=NGrams)\n",
    "    \n",
    "    # Define X_train and X_test\n",
    "    X_train_bow = vec_bow.fit_transform(X_train)\n",
    "    X_test_bow = vec_bow.transform(X_test)\n",
    "    \n",
    "    # Train the best model with the whole training set\n",
    "    model.fit(X_train_bow, y_train)\n",
    "    \n",
    "    # Make predictions on your data\n",
    "    y_pred = model.predict(X_test_bow)\n",
    "    \n",
    "    # Calculate the F1 score\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')  # Replace y_true with your true labels\n",
    "\n",
    "    # Store the results in a dictionary\n",
    "    results = {\n",
    "        'i': i,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "    # Append the results to the dataframe\n",
    "    results_log_df = results_log_df.append(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec84883b",
   "metadata": {},
   "source": [
    "## 2.1.1 Test performance nr of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0304cd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d5412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e84b5c3",
   "metadata": {},
   "source": [
    "## 2.1.2 Evaluate SVD performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "338e6220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77bc1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Document Frequency -- Maximum share of documents where a word needs to occur to be considered #\n",
    "MAXDF = 0.9\n",
    "\n",
    "# Maximum number of features we would want to consider -- ranked by most frequently occuring #\n",
    "MF= 10000\n",
    "\n",
    "# NGrams -- Number of Word Pairs. Takes the form (Min, Max). E.g. (1, 2) means single words and word pairs # \n",
    "NGrams = (1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a7939",
   "metadata": {},
   "source": [
    "Define the vectorizer itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16b832da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the vectorizer\n",
    "vec_bow = CountVectorizer(max_features= MF,\n",
    "                          max_df = MAXDF,\n",
    "                          ngram_range=NGrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60f9d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow = vec_bow.fit_transform(X_train)\n",
    "X_test_bow = vec_bow.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4f4b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sparse matrix to a dense array\n",
    "X_train_bow_arr = X_train_bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9871174e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['None', 'None', 'None', ..., 'Strategic alliance', 'None', 'None'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_arr = y_train.values\n",
    "y_train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95466fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models\n",
    "def get_models_svd():\n",
    "    models = dict()\n",
    "    for i in range(3000, 9001, 1000):\n",
    "        steps = [('svd', TruncatedSVD(n_components=i)), ('m', LogisticRegression())]\n",
    "        models[str(i)] = Pipeline(steps=steps)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "365f2be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    scores = cross_val_score(model, X, y, scoring= scoring, cv=cv, n_jobs= 2, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "268055f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3fc7a02fdabb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_bow_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-f955aa656773>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models_svd()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X_train_bow_arr, y_train_arr)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f486f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model performance for comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc0a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d8f9b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observation_nr</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.928801</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999932</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10809</th>\n",
       "      <td>10809</td>\n",
       "      <td>0.999587</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10810</th>\n",
       "      <td>10810</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10811</th>\n",
       "      <td>10811</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10812</th>\n",
       "      <td>10812</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10813</th>\n",
       "      <td>10813</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10814 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Observation_nr  Probability Prediction\n",
       "0                   0     0.928801       None\n",
       "1                   1     0.999932       None\n",
       "2                   2     0.999938       None\n",
       "3                   3     0.999660       None\n",
       "4                   4     0.999934       None\n",
       "...               ...          ...        ...\n",
       "10809           10809     0.999587       None\n",
       "10810           10810     0.999996       None\n",
       "10811           10811     0.999998       None\n",
       "10812           10812     0.999971       None\n",
       "10813           10813     0.999979       None\n",
       "\n",
       "[10814 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load predictions best model\n",
    "#predictions = pd.read_csv(\"./Output/predictions/bow_log_w.csv\", header = 0)\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ed18f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of df_test and create a new column 'Observation_nr'\n",
    "#df_test = df_test.reset_index().rename(columns={'index': 'Observation_nr'})\n",
    "\n",
    "# Merge the DataFrames based on 'Observation_nr'\n",
    "#merged_df = df_test.merge(predictions, on='Observation_nr', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b43541ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the merged DataFrame\n",
    "#merged_df = merged_df.drop(['id', 'Observation_nr'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24632f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.to_excel('Bettina.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2417927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
