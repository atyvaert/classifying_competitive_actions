{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf43c7f3",
   "metadata": {},
   "source": [
    "# B. Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e5b6d",
   "metadata": {},
   "source": [
    "# 0. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705a75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Packages #\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from scipy.stats import randint\n",
    "import random\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Load TQDM to Show Progress Bars #\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "\n",
    "# Sklearn Packages #\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# NLTK Packages #\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Import necessary libraries for handling imbalanced data\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3216d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off warnings, just to avoid pesky messages that might cause confusion here\n",
    "# Remove when testing your own code #\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d611c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Headline</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194578</td>\n",
       "      <td>Head Line: US Patent granted to BASF SE (Delaw...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>564295</td>\n",
       "      <td>Societe Generale Launches a Next-Generation Ca...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>504138</td>\n",
       "      <td>BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91379</td>\n",
       "      <td>ASML: 4Q Earnings Snapshot</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265750</td>\n",
       "      <td>Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           Headline category\n",
       "0  194578  Head Line: US Patent granted to BASF SE (Delaw...     None\n",
       "1  564295  Societe Generale Launches a Next-Generation Ca...     None\n",
       "2  504138  BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...     None\n",
       "3   91379                         ASML: 4Q Earnings Snapshot     None\n",
       "4  265750  Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...     None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to Working Directory with Training Data # \n",
    "os.chdir(\"/Users/Artur/Desktop/thesis_HIR_versie5/coding\")\n",
    "#os.chdir(\"/Users/juarel/Desktop/studies artur/thesis_HIR/coding\")\n",
    "\n",
    "\n",
    "# Load Training Data #\n",
    "df_train = pd.read_csv(\"./data/silver_data/train.csv\", header = 0)\n",
    "df_test = pd.read_csv(\"./data/silver_data/test.csv\", header = 0)\n",
    "\n",
    "# inspect the data\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08324f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NameCompany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andritz AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ams AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>voestalpine AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OMV AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wienerberger AG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NameCompany\n",
       "0       Andritz AG\n",
       "1           ams AG\n",
       "2   voestalpine AG\n",
       "3           OMV AG\n",
       "4  Wienerberger AG"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data about the different companies\n",
    "companies = pd.read_excel(\"./data/companies.xlsx\", header = 0)\n",
    "companies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2d651",
   "metadata": {},
   "source": [
    "# 1. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81c8b0d",
   "metadata": {},
   "source": [
    "## 1.1 Define custom tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce85e3",
   "metadata": {},
   "source": [
    "The first step when building our model is to clean the data. To perform this step, we need to define a custom tokenizer that will serve as input in our vectorizers. This tokenizer needs to fulfill the following criteria:\n",
    "\n",
    "1. We convert the strings to lowercase\n",
    "2. We remove currency symbols\n",
    "3. We remove punctuation from the text\n",
    "4. We remove English stopwords from the text as these do not provide any information to our model\n",
    "5. We remove numbers from the text. Note that numbers in combination with text are kept as they can provide information. For example, 4q gives an indication about an action in the fourth quarter.\n",
    "6. We remove words that with information linked to a specific company\n",
    "7. We remove words that consist out of a single character\n",
    "8. We lemmatize the words to reduce the words to their base form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca939d39",
   "metadata": {},
   "source": [
    "#### Create a list with words linked to a specific company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4bbf7",
   "metadata": {},
   "source": [
    "First, we create a set of all the unique words that could be linked to a company. These are the full company names (including legal suffixes) of which a part were used to retrieve the newswires and press releases from the NexisUni database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cbe42cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1137"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a list with the companies names to use in the tokenizer\n",
    "# Do not use this information in your model\n",
    "company_info = set()\n",
    "\n",
    "for name in companies['NameCompany']:\n",
    "    name = name.lower()\n",
    "    words = name.split()\n",
    "    company_info.update(words)\n",
    "\n",
    "len(company_info) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c31bd6",
   "metadata": {},
   "source": [
    "Then, we want to determine the set of words that does not contain any information about the company, such as legal prefixes. Therefore, we inspect which words are most frequently used in the names of the companies. When we inspected the results, we saw 1021 of the 1113 words were only used once over all the company names. These words can be seen as too company specific and will be removed from our headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d6a899",
   "metadata": {},
   "source": [
    "Determine a set of words that does not contain any information about the company:\n",
    "\n",
    "1. First, I convert the company names into lowercase and split the words. These results are stored in the column 'cleaned_name'. \n",
    "2. Then, I retrieve all these words and store them in the array 'company_names_array'. Note that these are not unique words, but just all the cleaned words from each company joined into one array.\n",
    "3. Next, I store the frequency of each word in a dataframe. \n",
    "4. Finally, I can determine which words are to company specific to be included in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "406a67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the company names\n",
    "def company_name_tokenizer(name):\n",
    "    # Remove special characters and digits\n",
    "    name = re.sub(r\"[^\\w\\s]\", \"\", name)\n",
    "    \n",
    "    # Convert the name to lowercase\n",
    "    name = name.lower()\n",
    "    \n",
    "    # Split the name into individual words\n",
    "    words = name.split()\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d118ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NameCompany</th>\n",
       "      <th>cleaned_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andritz AG</td>\n",
       "      <td>[andritz, ag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ams AG</td>\n",
       "      <td>[ams, ag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>voestalpine AG</td>\n",
       "      <td>[voestalpine, ag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OMV AG</td>\n",
       "      <td>[omv, ag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wienerberger AG</td>\n",
       "      <td>[wienerberger, ag]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NameCompany        cleaned_name\n",
       "0       Andritz AG       [andritz, ag]\n",
       "1           ams AG           [ams, ag]\n",
       "2   voestalpine AG   [voestalpine, ag]\n",
       "3           OMV AG           [omv, ag]\n",
       "4  Wienerberger AG  [wienerberger, ag]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a variable with the cleaned company names\n",
    "companies['cleaned_name'] = companies['NameCompany'].apply(company_name_tokenizer)\n",
    "companies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfcb00ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1021\n",
       "2      61\n",
       "3      20\n",
       "4       5\n",
       "6       4\n",
       "Name: Count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all the values from the cleaned company names and store them in an array\n",
    "company_names_array = np.concatenate(companies['cleaned_name'].values)\n",
    "\n",
    "# Count the frequency of each word in the array\n",
    "frequent_company_info = np.unique(company_names_array, return_counts=True)\n",
    "\n",
    "# Store the results in da dataframe\n",
    "word_frequencies = pd.DataFrame({'Word': frequent_company_info[0], \n",
    "                                'Count': frequent_company_info[1]})\n",
    "\n",
    "# Sort the dataframe in descending order by the 'Count' column\n",
    "word_frequencies = word_frequencies.sort_values('Count', ascending=False)\n",
    "word_frequencies['Count'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befaea1f",
   "metadata": {},
   "source": [
    "Create a set of the words that are not linked to a specific company. In other terms, words that were used more than once in a company description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e25601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe based on the count threshold\n",
    "general_voc = word_frequencies[word_frequencies['Count'] >= 2]['Word'].tolist()\n",
    "\n",
    "# Create a set from the filtered values\n",
    "general_voc = set(general_voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11438557",
   "metadata": {},
   "source": [
    "Remove these words from the initial set of words with all the company information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91255753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove these words from the set company info\n",
    "company_info = company_info.difference(general_voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a95cd4e",
   "metadata": {},
   "source": [
    "#### Define custom tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaef60a",
   "metadata": {},
   "source": [
    "Next, define the customer tokenizer that will be used as input in our vectorizers. Therefore, we use the information in company_info that we have just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a7d1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob_tokenizer(str_input):\n",
    "    \n",
    "    # Convert list to string\n",
    "    input_str = str_input\n",
    "    if isinstance(input_str, list):\n",
    "        input_str = ' '.join(input_str)\n",
    "        \n",
    "    # Remove currency symbols\n",
    "    str_input = re.sub(r'\\$|£|€', '', str_input)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    str_input = str_input.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Define stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Tokenize text\n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    \n",
    "    # Remove numbers, stop words, company information and words with one character\n",
    "    words = [word for word in tokens if not re.match('^\\d+$', word) and word not in stop_words\n",
    "                                        and word not in company_info and len(word) > 1]\n",
    "\n",
    "    # Lemmatize words\n",
    "    words = [Word(word).lemmatize() for word in words]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d24788e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_headline</th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>head u patent granted se delaware may titled c...</td>\n",
       "      <td>Head Line: US Patent granted to BASF SE (Delaw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>societe generale launch nextgeneration card in...</td>\n",
       "      <td>Societe Generale Launches a Next-Generation Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plc form communication</td>\n",
       "      <td>BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4q earnings snapshot</td>\n",
       "      <td>ASML: 4Q Earnings Snapshot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>form investment manager group plc</td>\n",
       "      <td>Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    cleaned_headline  \\\n",
       "0  head u patent granted se delaware may titled c...   \n",
       "1  societe generale launch nextgeneration card in...   \n",
       "2                             plc form communication   \n",
       "3                               4q earnings snapshot   \n",
       "4                  form investment manager group plc   \n",
       "\n",
       "                                            Headline  \n",
       "0  Head Line: US Patent granted to BASF SE (Delaw...  \n",
       "1  Societe Generale Launches a Next-Generation Ca...  \n",
       "2  BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...  \n",
       "3                         ASML: 4Q Earnings Snapshot  \n",
       "4  Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text data\n",
    "df_train['cleaned_headline'] = df_train['Headline'].apply(textblob_tokenizer)\n",
    "df_test['cleaned_headline'] = df_test['Headline'].apply(textblob_tokenizer)\n",
    "\n",
    "\n",
    "# check the cleaned data\n",
    "df_train[[\"cleaned_headline\", \"Headline\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d809e5",
   "metadata": {},
   "source": [
    "#### Define the number of unique words in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6416d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the rows in the 'cleaned_headline' column\n",
    "combined_text = ' '.join(df_train['cleaned_headline'])\n",
    "#combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8ebea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of unique words: 31978\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the combined text into words\n",
    "words = word_tokenize(combined_text)\n",
    "\n",
    "# Calculate the count of unique words\n",
    "unique_word_count = len(Counter(words))\n",
    "print(f' Number of unique words: {unique_word_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd8dc13",
   "metadata": {},
   "source": [
    "Check how many of these words have only one occurence: 19 094"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b1ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the count per word\n",
    "word_counts = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2af91cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19094\n",
       "2     4144\n",
       "3     1889\n",
       "4     1081\n",
       "5      726\n",
       "Name: Count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert word_counts dictionary to a DataFrame\n",
    "df_word_counts = pd.DataFrame.from_dict(word_counts, orient='index', columns=['Count'])\n",
    "df_word_counts = df_word_counts.sort_values(by='Count', ascending=False)\n",
    "df_word_counts['Count'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe33dc",
   "metadata": {},
   "source": [
    "## 1.2 Remove empty strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d518698",
   "metadata": {},
   "source": [
    "In the previous steps I have cleaned the data. However, it is possible that some headlines were so short that some cleaned headlines ended up being empty after the cleaning process. Therefore, I check if there are any empty strings present and removes these observations from my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "896a0831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43254, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, check the shape of the data before any operations\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc6fad2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Headline</th>\n",
       "      <th>category</th>\n",
       "      <th>cleaned_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10479</th>\n",
       "      <td>1115844</td>\n",
       "      <td>Sanofi</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13982</th>\n",
       "      <td>882908</td>\n",
       "      <td>Novartis</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18141</th>\n",
       "      <td>73986</td>\n",
       "      <td>/C O R R E C T I O N -- Allianz/</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23796</th>\n",
       "      <td>603479</td>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28534</th>\n",
       "      <td>1396642</td>\n",
       "      <td>Vodafone - 2017</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29702</th>\n",
       "      <td>1135568</td>\n",
       "      <td>Stada Arzneimittel</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37343</th>\n",
       "      <td>693912</td>\n",
       "      <td>Inchcape - 2017</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42065</th>\n",
       "      <td>872085</td>\n",
       "      <td>Nokia Corporation Nokia Corporation Financial -3-</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           Headline category  \\\n",
       "10479  1115844                                             Sanofi     None   \n",
       "13982   882908                                           Novartis     None   \n",
       "18141    73986                   /C O R R E C T I O N -- Allianz/     None   \n",
       "23796   603479                                    GlaxoSmithKline     None   \n",
       "28534  1396642                                    Vodafone - 2017     None   \n",
       "29702  1135568                                 Stada Arzneimittel     None   \n",
       "37343   693912                                    Inchcape - 2017     None   \n",
       "42065   872085  Nokia Corporation Nokia Corporation Financial -3-     None   \n",
       "\n",
       "      cleaned_headline  \n",
       "10479                   \n",
       "13982                   \n",
       "18141                   \n",
       "23796                   \n",
       "28534                   \n",
       "29702                   \n",
       "37343                   \n",
       "42065                   "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for empty strings after cleaning the data\n",
    "missing_data_train = df_train['cleaned_headline'].apply(lambda x: x == '')\n",
    "rows_with_empty_strings = df_train[missing_data_train]\n",
    "rows_with_empty_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef8806a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43246, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removes these empty strings from the dataset\n",
    "df_train = df_train[~missing_data_train]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "719f0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the same process to the test set (4 test observations were removed)\n",
    "missing_data_test = df_test['cleaned_headline'].apply(lambda x: x == '')\n",
    "df_test = df_test[~missing_data_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b05f3",
   "metadata": {},
   "source": [
    "## 1.3 Store the cleaned data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17ba9d0",
   "metadata": {},
   "source": [
    "The previous steps can be seen as preprocessing steps to clean the data. These steps will need to be performed each time we want to convert the textual data into numerical representations. Therefore, I write the data away as the gold data so I can easily retrieve the cleaned data in the other notebooks.\n",
    "\n",
    "In this notebook, we will keep using the column 'Headline' as independent variable as the text will get cleaned by the vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9987f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the adjusted train and test sets to CSV files\n",
    "df_train.to_csv('./data/gold_data/train.csv', index=False, encoding = 'utf-8')\n",
    "df_test.to_csv('./data/gold_data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1da09",
   "metadata": {},
   "source": [
    "# 2. Define functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccab087",
   "metadata": {},
   "source": [
    "Before we continue, we first define some useful functions, dataframes and parameters that we will use throughout this notebook:\n",
    "\n",
    "1. get_classification_metrics: Create a function that return the classification metrics for each model. The precision, recall and f1 score are all determined using the average value of all classes, without adjusting weights to these classes.\n",
    "\n",
    "2. Define a dataframe to store the results of the different models. Moreover, also define a dictionary that stores the best parameters for each model.\n",
    "\n",
    "3. Define the number of splits, the stratified cross validator to ensure class frequencies are considered, and the scoring metric based on the average F1 score. We use an F1 score as scoring metric as accuracy is not a good evaluation metric in our case.\n",
    "\n",
    "4. Define a function that trains the defined model, the input data, the classifier and its parameter grid. Besides, it will also take 4 parameters as input that give more information about the model that is being trained. This is usefull for the storage of the performance of the different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faf61e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Function that returns classication metrics\n",
    "def get_classification_metrics(y_true, y_pred):\n",
    "    \n",
    "    # Calculate Model Performance Metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4703149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create an empty dataframe to store the results of all the models\n",
    "results_all_df = pd.DataFrame()\n",
    "\n",
    "# Add columns for the metrics\n",
    "columns = ['vectorizer', 'FS', 'classifier', 'resampling','accuracy', 'precision', 'recall', 'f1']\n",
    "for col in columns:\n",
    "    results_all_df[col] = 0\n",
    "\n",
    "# create an empty dictionary to store the optimal parameters\n",
    "best_params_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d97903e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define different parameters\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize the stratified k-fold object\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42) # ensures class balances are kept\n",
    "\n",
    "# Define the scoring metric\n",
    "scoring = make_scorer(f1_score, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab34db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define a function to train and evaluate the different models\n",
    "def perform_grid_search(name, model, param_grid, X_train, X_test, y_train, y_test,\n",
    "                       vectorizer, FS, classifier, resampling):\n",
    "    \n",
    "    # Define a seed value\n",
    "    random.seed(7)\n",
    "        \n",
    "    # Perform the grid search using cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=skf, scoring=scoring)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model and its hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Store the best parameters for the current category in the dictionary\n",
    "    best_params_dict[name] = best_params\n",
    "    print(f'best parameters: {best_params}')\n",
    "\n",
    "    # Retrain the best model with the whole training set\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate the probabilities (not for SVM as this is not possible)\n",
    "    if classifier != 'SVM':\n",
    "        y_pred_proba = best_model.predict_proba(X_test)\n",
    "        \n",
    "        # Find the highest probability for each observation\n",
    "        highest_prob = np.amax(y_pred_proba, axis = 1)\n",
    "    \n",
    "        # Create a DataFrame with test observations, highest probabilities, and predicted classes\n",
    "        predictions_df = pd.DataFrame({'Observation_nr': y_test.index, 'Probability': highest_prob, 'Prediction': y_pred})\n",
    "        \n",
    "    else:\n",
    "        # Create a DataFrame with test observations and predicted classes\n",
    "        predictions_df = pd.DataFrame({'Observation_nr': y_test.index, 'Prediction': y_pred})\n",
    "        \n",
    "    # Store the final predictions with its probability for the test set\n",
    "    predictions_df.to_csv(f'./Output/predictions/{name}.csv', index = False, header = True)\n",
    "    #predictions_df.to_excel(f'./Output/predictions/{name}.xlsx', index = False, header = True)\n",
    "\n",
    "    # Calculate the classification metrics\n",
    "    accuracy, precision, recall, f1 = get_classification_metrics(y_test, y_pred)\n",
    "    \n",
    "    # print the results\n",
    "    print(f'Results for {name}:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1: {f1}')\n",
    "    \n",
    "    # add the results to the dataframe with all the results\n",
    "    results_all_df.loc[name] = [vectorizer, FS, classifier, resampling, accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96c6ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the independent and dependent variables\n",
    "X_train = df_train['Headline']\n",
    "X_test = df_test['Headline']\n",
    "\n",
    "y_train = df_train['category']\n",
    "y_test = df_test['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c12a88",
   "metadata": {},
   "source": [
    "# 3. Vectorizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c55ca4",
   "metadata": {},
   "source": [
    "In this notebook, I will test the performance of two vectorizers to transform the textual data into numerical representations. For each vectorizer, I will train and evaluate the 5 following classifiers through cross validation:\n",
    "\n",
    "1. Logistic Regression (normal + Ridge and Lasso variations)\n",
    "2. Decision Tree\n",
    "3. Support Vector Machine\n",
    "4. Random Forest\n",
    "5. Adaboost Classifier\n",
    "\n",
    "Each model is initialized the first time they are used (section 3.1). Moreover, I hypertune the parameters of each model trough cross validation with GridSearchCV. These parameters are defined when a new model is initialized. More information about these parameters can be found in the comments or in their sklearn documentation.\n",
    "\n",
    "Further, I tried to adress the class imbalance issue in the dataset with two resampling techniques:\n",
    "\n",
    "1. Random undersampling\n",
    "2. Oversampling through SMOTE\n",
    "\n",
    "For each base classifier, I will train the 5 base classifiers once without resampling technique, once with random undersampling and once with oversampling through SMOTE. When I have defined the right parameters for each model, I train and evaluate each model with the previously defined function perform_grid_search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc61da4",
   "metadata": {},
   "source": [
    "## 3.1 Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82774a3f",
   "metadata": {},
   "source": [
    "The first vectorizer that we will use to transform our textual data into numerical presentations is the bag of words procedure or BOW. In this approach, each headline is treated as a collection of individual words. Then, the vectorizer just indicates the frequency of each feature (=word) in the document. This is a simple and inexpensive approach to represent textual data into a numerical form. However, note that this will result in a sparse matrix due to the high number of words that we use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d50f03",
   "metadata": {},
   "source": [
    "Define the parameters of the vectorizer:\n",
    "\n",
    "1. Max_df = Maximum Document Frequency: Maximum share of documents where a word can occur to be considered as a feature. This value is set as 0.9 as to frequent occuring words lose their predictive value.\n",
    "\n",
    "2. Max_features = Maximum number of features we would want to consider, ranked by most frequently occuring. This value is set at 10.000. This value was found to work best with the different models after try and error. Considering our dataset only consists out of 31.798 words, of which only 12.884 appear more than once, we consider this a good cut-off point. Moreover, we only have 43.254 training observations which is relatively litte for this number of features. However, a lower number of features led to lower results.\n",
    "\n",
    "3. Ngram_range = Number of Word Pairs. In our case, we include unigrams and bigrams. \n",
    "\n",
    "4. Tokenizer = We use our customer defined tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04cbfa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Document Frequency -- Maximum share of documents where a word needs to occur to be considered #\n",
    "MAXDF = 0.9\n",
    "\n",
    "# Maximum number of features we would want to consider -- ranked by most frequently occuring #\n",
    "MF= 10000\n",
    "\n",
    "# NGrams -- Number of Word Pairs. Takes the form (Min, Max). E.g. (1, 2) means single words and word pairs # \n",
    "NGrams = (1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab74ed0",
   "metadata": {},
   "source": [
    "Define the vectorizer itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "454fb3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the vectorizer\n",
    "vec_bow = CountVectorizer(max_features= MF,\n",
    "                          min_df = MINDF,\n",
    "                          max_df = MAXDF,\n",
    "                          ngram_range= NGrams,\n",
    "                          tokenizer=textblob_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9b08a",
   "metadata": {},
   "source": [
    "Transform the textual data into numerical representations with the BOW vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3da4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the BOW vectorizer (train on training data and transform test set after)\n",
    "X_train_bow = vec_bow.fit_transform(X_train)\n",
    "X_test_bow = vec_bow.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2c76a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43254, 10000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape (= observations and features)\n",
    "X_train_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d7e5eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define with what vectorizer we build the models for storage:\n",
    "vectorizer = 'BOW'\n",
    "FS = 'None' # Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bb63da",
   "metadata": {},
   "source": [
    "### 2.1.1 Without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a7f0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique for storage\n",
    "resampling = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c32853",
   "metadata": {},
   "source": [
    "#### A. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "feb03e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_log_w'\n",
    "classifier = 'logR'\n",
    "\n",
    "# Initialize the classifier\n",
    "logreg = LogisticRegression(random_state = 7)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_log = {\n",
    "    'penalty': ['None','l1', 'l2'], # normal, lasso or ridge regression\n",
    "    'C': [0.1, 1, 10]               # The inverse penalization term (smaller is higher penalization)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0bc2428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Results for bow_log_w:\n",
      "Accuracy: 0.9250046236360274\n",
      "Precision: 0.5754734113499761\n",
      "Recall: 0.4509983700061958\n",
      "F1: 0.5004020041019801\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_bow, X_test_bow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb18666",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b663d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_DT_w'\n",
    "classifier = 'DT'\n",
    "\n",
    "# Initialize the classifier\n",
    "tree = DecisionTreeClassifier(random_state = 7)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_DT = {\n",
    "    'criterion': ['gini'],          # Define the splitting criteria: Gini index for node impurity\n",
    "    'min_samples_leaf': [1, 2],     # Define the minimum number of samples required to be at leaf node\n",
    "    'max_features': [None, 'sqrt']  # Define the number of features to consider when looking for the best split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e38d4198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1}\n",
      "Results for bow_DT_w:\n",
      "Accuracy: 0.9028111707046421\n",
      "Precision: 0.439957542538443\n",
      "Recall: 0.38526227710768074\n",
      "F1: 0.40142069121901386\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_bow, X_test_bow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87582e6",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba127b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_svm_w'\n",
    "classifier = 'SVM'\n",
    "\n",
    "# Initialize the classifier\n",
    "svm = SVC(random_state = 7)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100], # inverse regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf'], # what type of kernel need to be used (rbf = radial kernel)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47a7dca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Results for bow_svm_w:\n",
      "Accuracy: 0.9279637506935454\n",
      "Precision: 0.645338613690608\n",
      "Recall: 0.4175187919853814\n",
      "F1: 0.49216364262856055\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_bow, X_test_bow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d27ae5",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa3955b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_rf_w'\n",
    "classifier = 'RF'\n",
    "\n",
    "# Initialize the classifier\n",
    "rfc = RandomForestClassifier(random_state = 7, n_jobs = -1)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'criterion': ['gini'],          # Define the splitting criteria: Gini index for node impurity\n",
    "    'n_estimators': [100, 500],     # the number of trees to use when building the model\n",
    "    'min_samples_leaf': [1, 2],     # Define the minimum number of samples required to be at leaf node\n",
    "    'max_features': [None, 'sqrt']  # Define the number of features to consider when looking for the best split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14eac49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1, 'n_estimators': 500}\n",
      "Results for bow_rf_w:\n",
      "Accuracy: 0.9138154244497874\n",
      "Precision: 0.5344243514571876\n",
      "Recall: 0.38604668518371527\n",
      "F1: 0.4274280615651013\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_bow, X_test_bow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5bd69e",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce9de3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_ada_w'\n",
    "classifier = 'ADA'\n",
    "\n",
    "# Initialize decision tree base estimator for AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(random_state = 7)\n",
    "\n",
    "# Initialize AdaBoost classifier\n",
    "ada = AdaBoostClassifier(base_estimator = base_estimator, random_state = 7)\n",
    "\n",
    "# Define parameter grid for AdaBoost\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [50, 100, 250],   # the maximum number of estimators before boosting is terminated\n",
    "    'learning_rate': [0.1, 0.5, 1.0], # weight applied to each classifier at boosting iteration\n",
    "                                      # A higher learning rate increases the contribution of each classifier. \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96cf4aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Results for bow_ada_w:\n",
      "Accuracy: 0.9073423340114666\n",
      "Precision: 0.46030451726116195\n",
      "Recall: 0.3582422517873078\n",
      "F1: 0.39445416090086666\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_bow, X_test_bow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40b2e5",
   "metadata": {},
   "source": [
    "### 2.1.2 With Random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0efd195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Und'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ac4e41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categories and the maximum number of samples\n",
    "categories = df_train[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4701c802",
   "metadata": {},
   "source": [
    "#### Random undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078d77b9",
   "metadata": {},
   "source": [
    "To undersample the data, I decided to use the random undersampling technique. This technique just randomly eliminates observations from the majority class until the majority and minority class have the same number of observations. However, in the multiclass setting with multiple minority classes, it eliminates observations of all classes until they reach the same number of observations as the smallest minority class. In this scenario, a lot of the information in the dataset is thrown away. Therefore, I decided to follow another approach. I downsampled all categories to 4 times the number of observations of the smallest class. This way, the class imbalance is heavily reduced until a 4:1 imbalance ratio, but much more information is retained in the dataset. Besides, the second approach gave better results when evaluating my models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dc2794",
   "metadata": {},
   "source": [
    "#### Second strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36f8b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of samples in the smallest minority category\n",
    "rus_n = df_train['category'].value_counts().sort_values(ascending=False)[1]\n",
    "\n",
    "# Dictionary to store the actual maximum imbalance per class\n",
    "max_imbalance_u = {}\n",
    "\n",
    "# Calculate the actual maximum imbalance for each class\n",
    "for category in categories:\n",
    "    if category == 'None':\n",
    "        max_imbalance_u[category] = rus_n\n",
    "    else:\n",
    "        # Set the actual maximum to the number of available samples\n",
    "        max_imbalance_u[category] = y_train.value_counts()[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c83283d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                                                           797\n",
       "Strategic alliance                                             797\n",
       "Corporate \\ngovernance                                         597\n",
       "New product introduction/\\nservice offering                    518\n",
       "Merger & \\nacquisitions                                        460\n",
       "Financing                                                      262\n",
       "Product/\\nservice improvement                                  254\n",
       "Venturing                                                      250\n",
       "Expansion in existing market (product/service/geographical)    249\n",
       "Production-related actions                                     212\n",
       "Marketing                                                      205\n",
       "Divestiture                                                    199\n",
       "Human resources                                                161\n",
       "R&D-related actions                                            138\n",
       "Market entry                                                    76\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the random undersampler with maximum imbalance\n",
    "undersampler = RandomUnderSampler(sampling_strategy = max_imbalance_u, random_state = 7)\n",
    "\n",
    "# Undersample the data\n",
    "X_train_bow_und, y_train_bow_und = undersampler.fit_resample(X_train_bow, y_train)\n",
    "y_train_bow_und.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd752072",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7c39c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_log_u'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc6f1ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 1, 'penalty': 'l2'}\n",
      "Results for bow_log_u:\n",
      "Accuracy: 0.8240244127982245\n",
      "Precision: 0.35076021791522727\n",
      "Recall: 0.6572033669036993\n",
      "F1: 0.43505098444332013\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_bow_und, X_test_bow, y_train_bow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77751dd0",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "294863fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_DT_u'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93c34879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 2}\n",
      "Results for bow_DT_u:\n",
      "Accuracy: 0.7658590715738857\n",
      "Precision: 0.2596338426130034\n",
      "Recall: 0.5777130538199041\n",
      "F1: 0.3364276176926325\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_bow_und, X_test_bow, y_train_bow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb224122",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50569b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_svm_u'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b5a7ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 1, 'kernel': 'linear'}\n",
      "Results for bow_svm_u:\n",
      "Accuracy: 0.7852783428888478\n",
      "Precision: 0.2876350950340012\n",
      "Recall: 0.6385497060350971\n",
      "F1: 0.377265994719291\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_bow_und, X_test_bow, y_train_bow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8cd8d6",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ada17123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_rf_u'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e835e960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 2, 'n_estimators': 100}\n",
      "Results for bow_rf_u:\n",
      "Accuracy: 0.8017384871462918\n",
      "Precision: 0.28664982532638317\n",
      "Recall: 0.59171962553755\n",
      "F1: 0.36732559232507\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_bow_und, X_test_bow, y_train_bow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c76cc2",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bef66e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_ada_u'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0214c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Results for bow_ada_u:\n",
      "Accuracy: 0.7069539485851674\n",
      "Precision: 0.23804587757702966\n",
      "Recall: 0.5491769284022234\n",
      "F1: 0.3019865445836417\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_bow_und, X_test_bow, y_train_bow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc769c64",
   "metadata": {},
   "source": [
    "### 2.1.3 With oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1dafedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Ove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab748192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of samples in the majority class\n",
    "ove_n = df_train['category'].value_counts().sort_values(ascending=False)[0]\n",
    "\n",
    "# Oversample until the number of observations equals a fourth of the majority class\n",
    "max_samples = int(ove_n/4)\n",
    "\n",
    "# Dictionary to store the actual maximum imbalance per class\n",
    "max_imbalance = {}\n",
    "\n",
    "# Calculate the actual maximum imbalance for each class\n",
    "for category in categories:\n",
    "    if category == 'None':\n",
    "        max_imbalance[category] = y_train.value_counts()[category]\n",
    "    else:\n",
    "        # Set the actual maximum to the number of available samples\n",
    "        max_imbalance[category] = max_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17c54e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                                                           38876\n",
       "R&D-related actions                                             9719\n",
       "Human resources                                                 9719\n",
       "Venturing                                                       9719\n",
       "Market entry                                                    9719\n",
       "Divestiture                                                     9719\n",
       "Product/\\nservice improvement                                   9719\n",
       "Merger & \\nacquisitions                                         9719\n",
       "Financing                                                       9719\n",
       "Marketing                                                       9719\n",
       "Expansion in existing market (product/service/geographical)     9719\n",
       "Corporate \\ngovernance                                          9719\n",
       "Production-related actions                                      9719\n",
       "New product introduction/\\nservice offering                     9719\n",
       "Strategic alliance                                              9719\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the SMOTE oversampler\n",
    "oversampler = SMOTE(sampling_strategy=max_imbalance, random_state=7)\n",
    "\n",
    "# Undersample the data\n",
    "X_train_bow_ove, y_train_bow_ove = oversampler.fit_resample(X_train_bow, y_train)\n",
    "y_train_bow_ove.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3e0aa",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e731af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_log_o'\n",
    "classifier = 'logR'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d307746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Results for bow_log_o:\n",
      "Accuracy: 0.8957832439430368\n",
      "Precision: 0.41627749268059494\n",
      "Recall: 0.4966884459241199\n",
      "F1: 0.4492320023275047\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_bow_ove, X_test_bow, y_train_bow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b41767",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d08c63da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_DT_o'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d42368b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1}\n",
      "Results for bow_DT_o:\n",
      "Accuracy: 0.833179212132421\n",
      "Precision: 0.2879363227925523\n",
      "Recall: 0.5086591393544257\n",
      "F1: 0.35134370930114506\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_bow_ove, X_test_bow, y_train_bow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb2138",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8b9fadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_svm_o'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46798c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Results for bow_svm_o:\n",
      "Accuracy: 0.9032735343073793\n",
      "Precision: 0.4533061079062824\n",
      "Recall: 0.2613801709573333\n",
      "F1: 0.31790519961634706\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_bow_ove, X_test_bow, y_train_bow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e739f4",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3fe5a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_rf_o'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df561e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "Results for bow_rf_o:\n",
      "Accuracy: 0.8595339374884409\n",
      "Precision: 0.32853107368024237\n",
      "Recall: 0.5627928725918646\n",
      "F1: 0.40031240229571474\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_bow_ove, X_test_bow, y_train_bow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1015a",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba687ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_ada_o'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a78eb5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Results for bow_ada_o:\n",
      "Accuracy: 0.8404845570556686\n",
      "Precision: 0.2947507499988248\n",
      "Recall: 0.5070041802197532\n",
      "F1: 0.35765280109674674\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_bow_ove, X_test_bow, y_train_bow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8c813ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write away results\n",
    "results_all_df.to_csv('./Output/Model performance/results_BOW.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f3004f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dictionary with the best parameters away\n",
    "with open('./Output/parameters/BOW.json', 'w') as file:\n",
    "    json.dump(best_params_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71433dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
