{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a030b474",
   "metadata": {},
   "source": [
    "# B. Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79aaeaa",
   "metadata": {},
   "source": [
    "# 0. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e45ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Packages #\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from scipy.stats import randint\n",
    "import random\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Load TQDM to Show Progress Bars #\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "\n",
    "# Sklearn Packages #\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# NLTK Packages #\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Import necessary libraries for handling imbalanced data\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa6edad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off warnings, just to avoid pesky messages that might cause confusion here\n",
    "# Remove when testing your own code #\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95440a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Headline</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194578</td>\n",
       "      <td>Head Line: US Patent granted to BASF SE (Delaw...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>564295</td>\n",
       "      <td>Societe Generale Launches a Next-Generation Ca...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>504138</td>\n",
       "      <td>BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91379</td>\n",
       "      <td>ASML: 4Q Earnings Snapshot</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265750</td>\n",
       "      <td>Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           Headline category\n",
       "0  194578  Head Line: US Patent granted to BASF SE (Delaw...     None\n",
       "1  564295  Societe Generale Launches a Next-Generation Ca...     None\n",
       "2  504138  BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...     None\n",
       "3   91379                         ASML: 4Q Earnings Snapshot     None\n",
       "4  265750  Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...     None"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to Working Directory with Training Data # \n",
    "os.chdir(\"/Users/Artur/Desktop/thesis_HIR_versie5/coding\")\n",
    "#os.chdir(\"/Users/juarel/Desktop/studies artur/thesis_HIR/coding\")\n",
    "\n",
    "\n",
    "# Load Training Data #\n",
    "df_train = pd.read_csv(\"./data/silver_data/train.csv\", header = 0)\n",
    "df_test = pd.read_csv(\"./data/silver_data/test.csv\", header = 0)\n",
    "\n",
    "# inspect the data\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5a795ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NameCompany</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andritz AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ams AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>voestalpine AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OMV AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wienerberger AG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NameCompany\n",
       "0       Andritz AG\n",
       "1           ams AG\n",
       "2   voestalpine AG\n",
       "3           OMV AG\n",
       "4  Wienerberger AG"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data about the different companies\n",
    "companies = pd.read_excel(\"./data/companies.xlsx\", header = 0)\n",
    "companies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a437f185",
   "metadata": {},
   "source": [
    "# 1. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54657add",
   "metadata": {},
   "source": [
    "## 1.1 Define custom tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87892f7",
   "metadata": {},
   "source": [
    "The first step when building our model is to clean the data. To perform this step, we need to define a custom tokenizer that will serve as input in our vectorizers. This tokenizer needs to fulfill the following criteria:\n",
    "\n",
    "1. We convert the strings to lowercase\n",
    "2. We remove currency symbols\n",
    "3. We remove punctuation from the text\n",
    "4. We remove English stopwords from the text as these do not provide any information to our model\n",
    "5. We remove numbers from the text. Note that numbers in combination with text are kept as they can provide information. For example, 4q gives an indication about an action in the fourth quarter.\n",
    "6. We remove words that with information linked to a specific company\n",
    "7. We remove words that consist out of a single character\n",
    "8. We lemmatize the words to reduce the words to their base form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff610751",
   "metadata": {},
   "source": [
    "#### Create a list with words linked to a specific company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788bab94",
   "metadata": {},
   "source": [
    "First, we create a set of all the unique words that could be linked to a company. These are the full company names (including legal suffixes) of which a part were used to retrieve the newswires and press releases from the NexisUni database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686bb12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1137"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a list with the companies names to use in the tokenizer\n",
    "# Do not use this information in your model\n",
    "company_info = set()\n",
    "\n",
    "for name in companies['NameCompany']:\n",
    "    name = name.lower()\n",
    "    words = name.split()\n",
    "    company_info.update(words)\n",
    "\n",
    "len(company_info) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdacb28",
   "metadata": {},
   "source": [
    "Then, we want to determine the set of words that does not contain any information about the company, such as legal prefixes. Therefore, we inspect which words are most frequently used in the names of the companies. When we inspected the results, we saw 1021 of the 1113 words were only used once over all the company names. These words can be seen as too company specific and will be removed from our headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd98f79",
   "metadata": {},
   "source": [
    "Determine a set of words that does not contain any information about the company:\n",
    "\n",
    "1. First, I convert the company names into lowercase and split the words. These results are stored in the column 'cleaned_name'. \n",
    "2. Then, I retrieve all these words and store them in the array 'company_names_array'. Note that these are not unique words, but just all the cleaned words from each company joined into one array.\n",
    "3. Next, I store the frequency of each word in a dataframe. \n",
    "4. Finally, I can determine which words are to company specific to be included in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50968b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the company names\n",
    "def company_name_tokenizer(name):\n",
    "    # Remove special characters and digits\n",
    "    name = re.sub(r\"[^\\w\\s]\", \"\", name)\n",
    "    \n",
    "    # Convert the name to lowercase\n",
    "    name = name.lower()\n",
    "    \n",
    "    # Split the name into individual words\n",
    "    words = name.split()\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b60013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NameCompany</th>\n",
       "      <th>cleaned_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andritz AG</td>\n",
       "      <td>[andritz, ag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ams AG</td>\n",
       "      <td>[ams, ag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>voestalpine AG</td>\n",
       "      <td>[voestalpine, ag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OMV AG</td>\n",
       "      <td>[omv, ag]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wienerberger AG</td>\n",
       "      <td>[wienerberger, ag]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NameCompany        cleaned_name\n",
       "0       Andritz AG       [andritz, ag]\n",
       "1           ams AG           [ams, ag]\n",
       "2   voestalpine AG   [voestalpine, ag]\n",
       "3           OMV AG           [omv, ag]\n",
       "4  Wienerberger AG  [wienerberger, ag]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a variable with the cleaned company names\n",
    "companies['cleaned_name'] = companies['NameCompany'].apply(company_name_tokenizer)\n",
    "companies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ced05dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1021\n",
       "2      61\n",
       "3      20\n",
       "4       5\n",
       "6       4\n",
       "Name: Count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all the values from the cleaned company names and store them in an array\n",
    "company_names_array = np.concatenate(companies['cleaned_name'].values)\n",
    "\n",
    "# Count the frequency of each word in the array\n",
    "frequent_company_info = np.unique(company_names_array, return_counts=True)\n",
    "\n",
    "# Store the results in da dataframe\n",
    "word_frequencies = pd.DataFrame({'Word': frequent_company_info[0], \n",
    "                                'Count': frequent_company_info[1]})\n",
    "\n",
    "# Sort the dataframe in descending order by the 'Count' column\n",
    "word_frequencies = word_frequencies.sort_values('Count', ascending=False)\n",
    "word_frequencies['Count'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b66ec",
   "metadata": {},
   "source": [
    "Create a set of the words that are not linked to a specific company. In other terms, words that were used more than once in a company description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41d62760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe based on the count threshold\n",
    "general_voc = word_frequencies[word_frequencies['Count'] >= 2]['Word'].tolist()\n",
    "\n",
    "# Create a set from the filtered values\n",
    "general_voc = set(general_voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556d0ad",
   "metadata": {},
   "source": [
    "Remove these words from the initial set of words with all the company information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6cd9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove these words from the set company info\n",
    "company_info = company_info.difference(general_voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a4052",
   "metadata": {},
   "source": [
    "#### Define custom tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d8144",
   "metadata": {},
   "source": [
    "Next, define the customer tokenizer that will be used as input in our vectorizers. Therefore, we use the information in company_info that we have just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "710864ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob_tokenizer(str_input):\n",
    "    \n",
    "    # Convert list to string\n",
    "    input_str = str_input\n",
    "    if isinstance(input_str, list):\n",
    "        input_str = ' '.join(input_str)\n",
    "        \n",
    "    # Remove currency symbols\n",
    "    str_input = re.sub(r'\\$|£|€', '', str_input)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    str_input = str_input.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Define stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Tokenize text\n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    \n",
    "    # Remove numbers, stop words, company information and words with one character\n",
    "    words = [word for word in tokens if not re.match('^\\d+$', word) and word not in stop_words\n",
    "                                        and word not in company_info and len(word) > 1]\n",
    "\n",
    "    # Lemmatize words\n",
    "    words = [Word(word).lemmatize() for word in words]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b53142d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_headline</th>\n",
       "      <th>Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>head u patent granted se delaware may titled c...</td>\n",
       "      <td>Head Line: US Patent granted to BASF SE (Delaw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>societe generale launch nextgeneration card in...</td>\n",
       "      <td>Societe Generale Launches a Next-Generation Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plc form communication</td>\n",
       "      <td>BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4q earnings snapshot</td>\n",
       "      <td>ASML: 4Q Earnings Snapshot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>form investment manager group plc</td>\n",
       "      <td>Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    cleaned_headline  \\\n",
       "0  head u patent granted se delaware may titled c...   \n",
       "1  societe generale launch nextgeneration card in...   \n",
       "2                             plc form communication   \n",
       "3                               4q earnings snapshot   \n",
       "4                  form investment manager group plc   \n",
       "\n",
       "                                            Headline  \n",
       "0  Head Line: US Patent granted to BASF SE (Delaw...  \n",
       "1  Societe Generale Launches a Next-Generation Ca...  \n",
       "2  BARCLAYS PLC Form 8.3 - EUTELSAT COMMUNICATION...  \n",
       "3                         ASML: 4Q Earnings Snapshot  \n",
       "4  Form 8.3 - AXA INVESTMENT MANAGERS : Booker Gr...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text data\n",
    "df_train['cleaned_headline'] = df_train['Headline'].apply(textblob_tokenizer)\n",
    "df_test['cleaned_headline'] = df_test['Headline'].apply(textblob_tokenizer)\n",
    "\n",
    "\n",
    "# check the cleaned data\n",
    "df_train[[\"cleaned_headline\", \"Headline\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b1102b",
   "metadata": {},
   "source": [
    "#### Define the number of unique words in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a679133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the rows in the 'cleaned_headline' column\n",
    "combined_text = ' '.join(df_train['cleaned_headline'])\n",
    "#combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44f3f0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of unique words: 4\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the combined text into words\n",
    "#words = word_tokenize(combined_text)\n",
    "\n",
    "# Calculate the count of unique words\n",
    "unique_word_count = len(Counter(words))\n",
    "print(f' Number of unique words: {unique_word_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfba3f4a",
   "metadata": {},
   "source": [
    "Check how many of these words have only one occurence: 19 094"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32ff10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the count per word\n",
    "word_counts = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6a50646",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4\n",
       "Name: Count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert word_counts dictionary to a DataFrame\n",
    "df_word_counts = pd.DataFrame.from_dict(word_counts, orient='index', columns=['Count'])\n",
    "df_word_counts = df_word_counts.sort_values(by='Count', ascending=False)\n",
    "df_word_counts['Count'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aa036a",
   "metadata": {},
   "source": [
    "## 1.2 Remove empty strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2951c51",
   "metadata": {},
   "source": [
    "In the previous steps I have cleaned the data. However, it is possible that some headlines were so short that some cleaned headlines ended up being empty after the cleaning process. Therefore, I check if there are any empty strings present and removes these observations from my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2897c39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43254, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, check the shape of the data before any operations\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d54a12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Headline</th>\n",
       "      <th>category</th>\n",
       "      <th>cleaned_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10479</th>\n",
       "      <td>1115844</td>\n",
       "      <td>Sanofi</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13982</th>\n",
       "      <td>882908</td>\n",
       "      <td>Novartis</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18141</th>\n",
       "      <td>73986</td>\n",
       "      <td>/C O R R E C T I O N -- Allianz/</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23796</th>\n",
       "      <td>603479</td>\n",
       "      <td>GlaxoSmithKline</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28534</th>\n",
       "      <td>1396642</td>\n",
       "      <td>Vodafone - 2017</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29702</th>\n",
       "      <td>1135568</td>\n",
       "      <td>Stada Arzneimittel</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37343</th>\n",
       "      <td>693912</td>\n",
       "      <td>Inchcape - 2017</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42065</th>\n",
       "      <td>872085</td>\n",
       "      <td>Nokia Corporation Nokia Corporation Financial -3-</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           Headline category  \\\n",
       "10479  1115844                                             Sanofi     None   \n",
       "13982   882908                                           Novartis     None   \n",
       "18141    73986                   /C O R R E C T I O N -- Allianz/     None   \n",
       "23796   603479                                    GlaxoSmithKline     None   \n",
       "28534  1396642                                    Vodafone - 2017     None   \n",
       "29702  1135568                                 Stada Arzneimittel     None   \n",
       "37343   693912                                    Inchcape - 2017     None   \n",
       "42065   872085  Nokia Corporation Nokia Corporation Financial -3-     None   \n",
       "\n",
       "      cleaned_headline  \n",
       "10479                   \n",
       "13982                   \n",
       "18141                   \n",
       "23796                   \n",
       "28534                   \n",
       "29702                   \n",
       "37343                   \n",
       "42065                   "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for empty strings after cleaning the data\n",
    "missing_data_train = df_train['cleaned_headline'].apply(lambda x: x == '')\n",
    "rows_with_empty_strings = df_train[missing_data_train]\n",
    "rows_with_empty_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0644a573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43246, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removes these empty strings from the dataset\n",
    "df_train = df_train[~missing_data_train]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6ae0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the same process to the test set (4 test observations were removed)\n",
    "missing_data_test = df_test['cleaned_headline'].apply(lambda x: x == '')\n",
    "df_test = df_test[~missing_data_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77528c53",
   "metadata": {},
   "source": [
    "## 1.3 Store the cleaned data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f50bf8",
   "metadata": {},
   "source": [
    "The previous steps can be seen as preprocessing steps to clean the data. These steps will need to be performed each time we want to convert the textual data into numerical representations. Therefore, I write the data away as the gold data so I can easily retrieve the cleaned data in the other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d668bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the adjusted train and test sets to CSV files\n",
    "df_train.to_csv('./data/gold_data/train.csv', index=False)\n",
    "df_test.to_csv('./data/gold_data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7186e429",
   "metadata": {},
   "source": [
    "# 2. Define functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198ee1c5",
   "metadata": {},
   "source": [
    "Before we continue, we first define some useful functions, dataframes and parameters that we will use throughout this notebook:\n",
    "\n",
    "1. get_classification_metrics: Create a function that return the classification metrics for each model. The precision, recall and f1 score are all determined using the average value of all classes, without adjusting weights to these classes.\n",
    "\n",
    "2. Define a dataframe to store the results of the different models. Moreover, also define a dictionary that stores the best parameters for each model.\n",
    "\n",
    "3. Define the number of splits, the stratified cross validator to ensure class frequencies are considered, and the scoring metric based on the average F1 score. We use an F1 score as scoring metric as accuracy is not a good evaluation metric in our case.\n",
    "\n",
    "4. Define a function that trains the defined model, the input data, the classifier and its parameter grid. Besides, it will also take 4 parameters as input that give more information about the model that is being trained. This is usefull for the storage of the performance of the different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14da29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Function that returns classication metrics\n",
    "def get_classification_metrics(y_true, y_pred):\n",
    "    \n",
    "    # Calculate Model Performance Metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2c6d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create an empty dataframe to store the results of all the models\n",
    "results_all_df = pd.DataFrame()\n",
    "\n",
    "# Add columns for the metrics\n",
    "columns = ['vectorizer', 'FS', 'classifier', 'resampling','accuracy', 'precision', 'recall', 'f1']\n",
    "for col in columns:\n",
    "    results_all_df[col] = 0\n",
    "\n",
    "# create an empty dictionary to store the optimal parameters\n",
    "best_params_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9edb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define different parameters\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize the stratified k-fold object\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42) # ensures class balances are kept\n",
    "\n",
    "# Define the scoring metric\n",
    "scoring = make_scorer(f1_score, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d68a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define a function to train and evaluate the different models\n",
    "def perform_grid_search(name, model, param_grid, X_train, X_test, y_train, y_test,\n",
    "                       vectorizer, FS, classifier, resampling):\n",
    "    \n",
    "    # Define a seed value\n",
    "    random.seed(7)\n",
    "        \n",
    "    # Perform the grid search using cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=skf, scoring=scoring)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model and its hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Store the best parameters for the current category in the dictionary\n",
    "    best_params_dict[name] = best_params\n",
    "    print(f'best parameters: {best_params}')\n",
    "\n",
    "    # Retrain the best model with the whole training set\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate the probabilities (not for SVM as this is not possible)\n",
    "    if classifier != 'SVM':\n",
    "        y_pred_proba = best_model.predict_proba(X_test)\n",
    "        \n",
    "        # Find the highest probability for each observation\n",
    "        highest_prob = np.amax(y_pred_proba, axis = 1)\n",
    "    \n",
    "        # Create a DataFrame with test observations, highest probabilities, and predicted classes\n",
    "        predictions_df = pd.DataFrame({'Observation_nr': y_test.index, 'Probability': highest_prob, 'Prediction': y_pred})\n",
    "        \n",
    "    else:\n",
    "        # Create a DataFrame with test observations and predicted classes\n",
    "        predictions_df = pd.DataFrame({'Observation_nr': y_test.index, 'Prediction': y_pred})\n",
    "        \n",
    "    # Store the final predictions with its probability for the test set\n",
    "    predictions_df.to_csv(f'./Output/predictions/{name}.csv', index = False, header = True)\n",
    "    #predictions_df.to_excel(f'./Output/predictions/{name}.xlsx', index = False, header = True)\n",
    "\n",
    "    # Calculate the classification metrics\n",
    "    accuracy, precision, recall, f1 = get_classification_metrics(y_test, y_pred)\n",
    "    \n",
    "    # print the results\n",
    "    print(f'Results for {name}:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1: {f1}')\n",
    "    \n",
    "    # add the results to the dataframe with all the results\n",
    "    results_all_df.loc[name] = [vectorizer, FS, classifier, resampling, accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22ca8b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the independent and dependent variables\n",
    "X_train = df_train['cleaned_headline']\n",
    "X_test = df_test['cleaned_headline']\n",
    "\n",
    "y_train = df_train['category']\n",
    "y_test = df_test['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bccb1a0",
   "metadata": {},
   "source": [
    "# 3. Vectorizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d18c68d",
   "metadata": {},
   "source": [
    "In this notebook, I will test the performance of two vectorizers to transform the textual data into numerical representations. For each vectorizer, I will train and evaluate the 5 following classifiers through cross validation:\n",
    "\n",
    "1. Logistic Regression (normal + Ridge and Lasso variations)\n",
    "2. Decision Tree\n",
    "3. Support Vector Machine\n",
    "4. Random Forest\n",
    "5. Adaboost Classifier\n",
    "\n",
    "Each model is initialized the first time they are used (section 3.1). Moreover, I hypertune the parameters of each model trough cross validation with GridSearchCV. These parameters are defined when a new model is initialized. More information about these parameters can be found in the comments or in their sklearn documentation.\n",
    "\n",
    "Further, I tried to adress the class imbalance issue in the dataset with two resampling techniques:\n",
    "\n",
    "1. Random undersampling\n",
    "2. Oversampling through SMOTE\n",
    "\n",
    "For each base classifier, I will train the 5 base classifiers once without resampling technique, once with random undersampling and once with oversampling through SMOTE. When I have defined the right parameters for each model, I train and evaluate each model with the previously defined function perform_grid_search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73268851",
   "metadata": {},
   "source": [
    "## 3.1 Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9d522",
   "metadata": {},
   "source": [
    "The first vectorizer that we will use to transform our textual data into numerical presentations is the bag of words procedure or BOW. In this approach, each headline is treated as a collection of individual words. Then, the vectorizer just indicates the frequency of each feature (=word) in the document. This is a simple and inexpensive approach to represent textual data into a numerical form. However, note that this will result in a sparse matrix due to the high number of words that we use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd80d431",
   "metadata": {},
   "source": [
    "Define the parameters of the vectorizer:\n",
    "\n",
    "1. Max_df = Maximum Document Frequency: Maximum share of documents where a word can occur to be considered as a feature. This value is set as 0.9 as to frequent occuring words lose their predictive value.\n",
    "\n",
    "2. Max_features = Maximum number of features we would want to consider, ranked by most frequently occuring. This value is set at 10.000. This value was found to work best with the different models after try and error. Considering our dataset only consists out of 31.798 words, of which only 12.884 appear more than once, we consider this a good cut-off point. Moreover, we only have 43.254 training observations which is relatively litte for this number of features. However, a lower number of features led to lower results.\n",
    "\n",
    "3. Ngram_range = Number of Word Pairs. In our case, we include unigrams and bigrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9ae8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Document Frequency -- Maximum share of documents where a word needs to occur to be considered #\n",
    "MAXDF = 0.9\n",
    "\n",
    "# Maximum number of features we would want to consider -- ranked by most frequently occuring #\n",
    "MF= 10000\n",
    "\n",
    "# NGrams -- Number of Word Pairs. Takes the form (Min, Max). E.g. (1, 2) means single words and word pairs # \n",
    "NGrams = (1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd148ec",
   "metadata": {},
   "source": [
    "Define the vectorizer itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a66cae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the vectorizer\n",
    "vec_bow = CountVectorizer(max_features= MF,\n",
    "                          max_df = MAXDF,\n",
    "                          ngram_range= NGrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9b29c9",
   "metadata": {},
   "source": [
    "Transform the textual data into numerical representations with the BOW vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "665a5661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the BOW vectorizer (train on training data and transform test set after)\n",
    "X_train_bow = vec_bow.fit_transform(X_train)\n",
    "X_test_bow = vec_bow.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9084c893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43246, 10000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape (= observations and features)\n",
    "X_train_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3112efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define with what vectorizer we build the models for storage:\n",
    "vectorizer = 'BOW'\n",
    "FS = 'None' # Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abfde66",
   "metadata": {},
   "source": [
    "### 3.1.1 Without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18a5e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique for storage\n",
    "resampling = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7598094f",
   "metadata": {},
   "source": [
    "#### A. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0fc65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_log_w'\n",
    "classifier = 'logR'\n",
    "\n",
    "# Initialize the classifier\n",
    "logreg = LogisticRegression(random_state = 7, multi_class = 'multinomial')\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_log = {\n",
    "    'penalty': [None, 'l2'], # normal, lasso or ridge regression\n",
    "    'C': [0.1, 1, 10]               # The inverse penalization term (smaller is higher penalization)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea8a2023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Results for bow_log_w:\n",
      "Accuracy: 0.9232192414431082\n",
      "Precision: 0.5589560028145996\n",
      "Recall: 0.4381128510794063\n",
      "F1: 0.4871981421292809\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_bow, X_test_bow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c711d61",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb6253f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_DT_w'\n",
    "classifier = 'DT'\n",
    "\n",
    "# Initialize the classifier\n",
    "tree = DecisionTreeClassifier(random_state = 7)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_DT = {\n",
    "    'criterion': ['gini'],          # Define the splitting criteria: Gini index for node impurity\n",
    "    'min_samples_leaf': [1, 2],     # Define the minimum number of samples required to be at leaf node\n",
    "    'max_features': [None]  # Define the number of features to consider when looking for the best split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "041a3f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1}\n",
      "Results for bow_DT_w:\n",
      "Accuracy: 0.9025901942645699\n",
      "Precision: 0.4533246650709703\n",
      "Recall: 0.3936014046553041\n",
      "F1: 0.408581857899067\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_bow, X_test_bow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d555320f",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68cc6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_svm_w'\n",
    "classifier = 'SVM'\n",
    "\n",
    "# Initialize the classifier\n",
    "svm = SVC(random_state = 7)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100], # inverse regularization parameter\n",
    "    'kernel': ['linear', 'poly', 'rbf'], # what type of kernel need to be used (rbf = radial kernel)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b0cf780",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-8fe3ca8f550c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# perform a grid search for the logistic regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# the results are automatically stored in results_all_df and best_params_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m perform_grid_search(model_name, svm, param_grid_svm, X_train_bow, X_test_bow, y_train, y_test,\n\u001b[0m\u001b[1;32m      4\u001b[0m                    vectorizer, FS, classifier, resampling)\n",
      "\u001b[0;32m<ipython-input-24-84f9eb7842a6>\u001b[0m in \u001b[0;36mperform_grid_search\u001b[0;34m(name, model, param_grid, X_train, X_test, y_train, y_test, vectorizer, FS, classifier, resampling)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Perform the grid search using cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Get the best model and its hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibsvm_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibsvm_sparse_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/_libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m\"\"\"base matrix class for compressed row- and column-oriented matrices\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_bow, X_test_bow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae78b8",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2822a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_rf_w'\n",
    "classifier = 'RF'\n",
    "\n",
    "# Initialize the classifier\n",
    "rfc = RandomForestClassifier(random_state = 7, n_jobs = -1)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'criterion': ['gini'],          # Define the splitting criteria: Gini index for node impurity\n",
    "    'n_estimators': [100, 500],     # the number of trees to use when building the model\n",
    "    'min_samples_leaf': [1, 2],     # Define the minimum number of samples required to be at leaf node\n",
    "    'max_features': [None, 'sqrt']  # Define the number of features to consider when looking for the best split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caec6ed1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c71dbbc1e3a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# perform a grid search for the logistic regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# the results are automatically stored in results_all_df and best_params_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m perform_grid_search(model_name, rfc, param_grid_rf, X_train_bow, X_test_bow, y_train, y_test,\n\u001b[0m\u001b[1;32m      4\u001b[0m                    vectorizer, FS, classifier, resampling)\n",
      "\u001b[0;32m<ipython-input-24-84f9eb7842a6>\u001b[0m in \u001b[0;36mperform_grid_search\u001b[0;34m(name, model, param_grid, X_train, X_test, y_train, y_test, vectorizer, FS, classifier, resampling)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Perform the grid search using cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Get the best model and its hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_bow, X_test_bow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88be3906",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abbeef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_ada_w'\n",
    "classifier = 'ADA'\n",
    "\n",
    "# Initialize decision tree base estimator for AdaBoost\n",
    "base_estimator = DecisionTreeClassifier(random_state = 7)\n",
    "\n",
    "# Initialize AdaBoost classifier\n",
    "ada = AdaBoostClassifier(estimator = base_estimator, random_state = 7)\n",
    "\n",
    "# Define parameter grid for AdaBoost\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [50, 100, 250],   # the maximum number of estimators before boosting is terminated\n",
    "    'learning_rate': [0.1, 0.5, 1.0], # weight applied to each classifier at boosting iteration\n",
    "                                      # A higher learning rate increases the contribution of each classifier. \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13472ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_bow, X_test_bow, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b467510d",
   "metadata": {},
   "source": [
    "### 3.1.2 With Random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55bd9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Und'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a31655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categories and the maximum number of samples\n",
    "categories = df_train[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff17cee",
   "metadata": {},
   "source": [
    "#### Random undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d916a",
   "metadata": {},
   "source": [
    "To undersample the data, I decided to use the random undersampling technique. This technique just randomly eliminates observations from the majority class until the majority and minority class have the same number of observations. However, in our multiclass setting with multiple minority classes, it eliminates observations of all classes until they reach the same number of observations as the smallest minority class. In this scenario, a lot of the information in the dataset is thrown away. \n",
    "\n",
    "Therefore, I decided to follow another approach. I downsampled all categories to 4 times the number of observations of the smallest class. This way, the class imbalance is heavily reduced until a 4:1 imbalance ratio, but much more information is retained in the dataset. Besides, the second approach gave better results when evaluating my models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a99fbd",
   "metadata": {},
   "source": [
    "#### Second strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "510b86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of samples in the smallest minority category\n",
    "rus_n = df_train['category'].value_counts().sort_values(ascending=False)[1]\n",
    "\n",
    "# Dictionary to store the actual maximum imbalance per class\n",
    "max_imbalance_u = {}\n",
    "\n",
    "# Calculate the actual maximum imbalance for each class\n",
    "for category in categories:\n",
    "    if category == 'None':\n",
    "        max_imbalance_u[category] = rus_n\n",
    "    else:\n",
    "        # Set the actual maximum to the number of available samples\n",
    "        max_imbalance_u[category] = y_train.value_counts()[category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05a287d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                                                           797\n",
       "Strategic alliance                                             797\n",
       "Corporate \\ngovernance                                         597\n",
       "New product introduction/\\nservice offering                    518\n",
       "Merger & \\nacquisitions                                        460\n",
       "Financing                                                      262\n",
       "Product/\\nservice improvement                                  254\n",
       "Venturing                                                      250\n",
       "Expansion in existing market (product/service/geographical)    249\n",
       "Production-related actions                                     212\n",
       "Marketing                                                      205\n",
       "Divestiture                                                    199\n",
       "Human resources                                                161\n",
       "R&D-related actions                                            138\n",
       "Market entry                                                    76\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the random undersampler with maximum imbalance\n",
    "undersampler = RandomUnderSampler(sampling_strategy = max_imbalance_u, random_state = 7)\n",
    "\n",
    "# Undersample the data\n",
    "X_train_bow_und, y_train_bow_und = undersampler.fit_resample(X_train_bow, y_train)\n",
    "y_train_bow_und.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e6caf1",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c9bcf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_log_u'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c174ce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 1, 'penalty': 'l2'}\n",
      "Results for bow_log_u:\n",
      "Accuracy: 0.8240244127982245\n",
      "Precision: 0.35076021791522727\n",
      "Recall: 0.6572033669036993\n",
      "F1: 0.43505098444332013\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_bow_und, X_test_bow, y_train_bow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d029469d",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84270959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_DT_u'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5906a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 2}\n",
      "Results for bow_DT_u:\n",
      "Accuracy: 0.7658590715738857\n",
      "Precision: 0.2596338426130034\n",
      "Recall: 0.5777130538199041\n",
      "F1: 0.3364276176926325\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_bow_und, X_test_bow, y_train_bow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52b454",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d92bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_svm_u'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "368cecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 1, 'kernel': 'linear'}\n",
      "Results for bow_svm_u:\n",
      "Accuracy: 0.7852783428888478\n",
      "Precision: 0.2876350950340012\n",
      "Recall: 0.6385497060350971\n",
      "F1: 0.377265994719291\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_bow_und, X_test_bow, y_train_bow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19f27aa",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "932b5cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_rf_u'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbee75b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 2, 'n_estimators': 100}\n",
      "Results for bow_rf_u:\n",
      "Accuracy: 0.8017384871462918\n",
      "Precision: 0.28664982532638317\n",
      "Recall: 0.59171962553755\n",
      "F1: 0.36732559232507\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_bow_und, X_test_bow, y_train_bow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a2a67",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4dc66240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_ada_u'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5f833ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Results for bow_ada_u:\n",
      "Accuracy: 0.7069539485851674\n",
      "Precision: 0.23804587757702966\n",
      "Recall: 0.5491769284022234\n",
      "F1: 0.3019865445836417\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_bow_und, X_test_bow, y_train_bow_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c4e4ab",
   "metadata": {},
   "source": [
    "### 3.1.3 With oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6b7a1d",
   "metadata": {},
   "source": [
    "#### Oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59a40cf",
   "metadata": {},
   "source": [
    "To undersample the data, I decided to use the Synthetic Minority Over-sampling technique or SMOTE. This is an oversampling technique that creates synthetic observations from the minority class until it the minority class and the majority class have the same number of observations. However, in our multiclass setting with multiple minority classes, it creates synthetic observations of each minority class until they each reach the same number of observations as the 'None' category. Moreover, our dataset also suffers from very large imbalance ratios. This means that a huge number of synthetic data observations need to created in our case.\n",
    "\n",
    "Therefore, I decided to follow another approach. I oversampled all minority categories until they reached a fourth of the number of observations of the majority class. Be aware that this approach still needs to create a large number of synthetic data observations, as I oversampled the smallest minority class from 76 to 9719 observations.\n",
    "This way, the class imbalance is heavily reduced until a 4:1 imbalance ratio, but the chances of overfitting the minority classes is increases significantly. However, this approach gives better than results than oversampling each category until the same number of observations is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "173eb5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Ove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bc0d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of samples in the majority class\n",
    "ove_n = df_train['category'].value_counts().sort_values(ascending=False)[0]\n",
    "\n",
    "# Oversample until the number of observations equals a fourth of the majority class\n",
    "max_samples = int(ove_n/4)\n",
    "\n",
    "# Dictionary to store the actual maximum imbalance per class\n",
    "max_imbalance_o = {}\n",
    "\n",
    "# Calculate the actual maximum imbalance for each class\n",
    "for category in categories:\n",
    "    if category == 'None':\n",
    "        max_imbalance_o[category] = y_train.value_counts()[category]\n",
    "    else:\n",
    "        # Set the actual maximum to the number of available samples\n",
    "        max_imbalance_o[category] = max_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e63177b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                                                           38876\n",
       "R&D-related actions                                             9719\n",
       "Human resources                                                 9719\n",
       "Venturing                                                       9719\n",
       "Market entry                                                    9719\n",
       "Divestiture                                                     9719\n",
       "Product/\\nservice improvement                                   9719\n",
       "Merger & \\nacquisitions                                         9719\n",
       "Financing                                                       9719\n",
       "Marketing                                                       9719\n",
       "Expansion in existing market (product/service/geographical)     9719\n",
       "Corporate \\ngovernance                                          9719\n",
       "Production-related actions                                      9719\n",
       "New product introduction/\\nservice offering                     9719\n",
       "Strategic alliance                                              9719\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the SMOTE oversampler\n",
    "oversampler = SMOTE(sampling_strategy=max_imbalance_o, random_state=7)\n",
    "\n",
    "# Undersample the data\n",
    "X_train_bow_ove, y_train_bow_ove = oversampler.fit_resample(X_train_bow, y_train)\n",
    "y_train_bow_ove.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d51bf",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30006e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_log_o'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25645a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Results for bow_log_o:\n",
      "Accuracy: 0.8957832439430368\n",
      "Precision: 0.41627749268059494\n",
      "Recall: 0.4966884459241199\n",
      "F1: 0.4492320023275047\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_bow_ove, X_test_bow, y_train_bow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d96a59",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50390436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_DT_o'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f3c75f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1}\n",
      "Results for bow_DT_o:\n",
      "Accuracy: 0.833179212132421\n",
      "Precision: 0.2879363227925523\n",
      "Recall: 0.5086591393544257\n",
      "F1: 0.35134370930114506\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_bow_ove, X_test_bow, y_train_bow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc0120",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3ea9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_svm_o'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f92b6d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Results for bow_svm_o:\n",
      "Accuracy: 0.9032735343073793\n",
      "Precision: 0.4533061079062824\n",
      "Recall: 0.2613801709573333\n",
      "F1: 0.31790519961634706\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_bow_ove, X_test_bow, y_train_bow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e08179f",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2fe01a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_rf_o'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f992cbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "Results for bow_rf_o:\n",
      "Accuracy: 0.8595339374884409\n",
      "Precision: 0.32853107368024237\n",
      "Recall: 0.5627928725918646\n",
      "F1: 0.40031240229571474\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_bow_ove, X_test_bow, y_train_bow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7020b1",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "baccffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'bow_ada_o'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "879d2272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Results for bow_ada_o:\n",
      "Accuracy: 0.8404845570556686\n",
      "Precision: 0.2947507499988248\n",
      "Recall: 0.5070041802197532\n",
      "F1: 0.35765280109674674\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_bow_ove, X_test_bow, y_train_bow_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d9620c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write away results\n",
    "results_all_df.to_csv('./Output/Model performance/results_BOW.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e65afc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dictionary with the best parameters away\n",
    "with open('./Output/parameters/BOW.json', 'w') as file:\n",
    "    json.dump(best_params_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440544ca",
   "metadata": {},
   "source": [
    "## 3.2 TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7f5353",
   "metadata": {},
   "source": [
    "The second vectorizer that I used to transform the textual data into a numerical representation is the term frequency inverse document frequency procedure of TF-IDF.\n",
    "\n",
    "This vectorizer..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c8ecdc",
   "metadata": {},
   "source": [
    "Define the parameters of the vectorizer, which are the same as for the BOW vectorizer:\n",
    "\n",
    "1. Max_df = Maximum Document Frequency: Maximum share of documents where a word can occur to be considered as a feature. This value is set as 0.9 as to frequent occuring words lose their predictive value.\n",
    "\n",
    "2. Max_features = Maximum number of features we would want to consider, ranked by most frequently occuring. This value is set at 10.000. This value was found to work best with the different models after try and error. Considering our dataset only consists out of 31.798 words, of which only 12.884 appear more than once, we consider this a good cut-off point. Moreover, we only have 43.254 training observations which is relatively litte for this number of features. However, a lower number of features led to lower results.\n",
    "\n",
    "3. Ngram_range = Number of Word Pairs. In our case, we include unigrams and bigrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ceb5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Document Frequency -- Maximum share of documents where a word needs to occur to be considered #\n",
    "MAXDF = 0.9\n",
    "\n",
    "# Maximum number of features we would want to consider -- ranked by most frequently occuring #\n",
    "MF= 10000\n",
    "\n",
    "# NGrams -- Number of Word Pairs. Takes the form (Min, Max). E.g. (1, 2) means single words and word pairs # \n",
    "NGrams = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vectorizer\n",
    "vec_tf_idf = TfidfVectorizer(max_features= MF,\n",
    "                      max_df = MAXDF,\n",
    "                      ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ba8ff",
   "metadata": {},
   "source": [
    "Transform the textual data into numerical representations with the TF_IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75a19c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the TF_IDF vectorizer (train on training data and transform test set after)\n",
    "X_train_tf_idf = vec_tf_idf.fit_transform(X_train)\n",
    "X_test_tf_idf = vec_tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d1a3321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43246, 10000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape (= observations and features)\n",
    "X_train_tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ecc95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define with what vectorizer we build the models for storage:\n",
    "vectorizer = 'TF_IDF'\n",
    "FS = 'None' # Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c90e8d",
   "metadata": {},
   "source": [
    "Next, we train and evaluate the different models using the same base classifiers and resampling techniques as for the BOW vectorizer. Note that this is exactly the same code as for the BOW vectorizer, but now repeated for the TF_IDF vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c16e51",
   "metadata": {},
   "source": [
    "### 3.2.1 Without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d94049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique for storage\n",
    "resampling = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f9261",
   "metadata": {},
   "source": [
    "#### A. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7965cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_log_w'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f094f34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Results for tf_idf_log_w:\n",
      "Accuracy: 0.9281486961346402\n",
      "Precision: 0.6479217426732929\n",
      "Recall: 0.4103027324054924\n",
      "F1: 0.4885864796913653\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_tf_idf, X_test_tf_idf, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9733bd",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d604b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_DT_w'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77d1e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1}\n",
      "Results for tf_idf_DT_w:\n",
      "Accuracy: 0.9048455705566858\n",
      "Precision: 0.43557291498844963\n",
      "Recall: 0.37687571107909934\n",
      "F1: 0.4002439156024365\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_tf_idf, X_test_tf_idf, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952519bc",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20787745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_svm_w'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ce3925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'kernel': 'linear'}\n",
      "Results for tf_idf_svm_w:\n",
      "Accuracy: 0.9189938968004439\n",
      "Precision: 0.5349927840807673\n",
      "Recall: 0.47136473365073533\n",
      "F1: 0.4971565034464318\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_tf_idf, X_test_tf_idf, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70729605",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4332537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_rf_w'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54cd6ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1, 'n_estimators': 100}\n",
      "Results for tf_idf_rf_w:\n",
      "Accuracy: 0.9191788422415388\n",
      "Precision: 0.5625846187084751\n",
      "Recall: 0.3619398188260086\n",
      "F1: 0.4243154369479495\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_tf_idf, X_test_tf_idf, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367a96c",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2afc9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_ada_w'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf18887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "Results for tf_idf_ada_w:\n",
      "Accuracy: 0.910578879230627\n",
      "Precision: 0.4590048346047768\n",
      "Recall: 0.32365649270902086\n",
      "F1: 0.3713918589725118\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_tf_idf, X_test_tf_idf, y_train, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3215ec",
   "metadata": {},
   "source": [
    "### 3.2.2 With undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9658f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Und'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5790dbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Strategic alliance                                             797\n",
       "None                                                           797\n",
       "Corporate \\ngovernance                                         597\n",
       "New product introduction/\\nservice offering                    518\n",
       "Merger & \\nacquisitions                                        460\n",
       "Financing                                                      262\n",
       "Product/\\nservice improvement                                  254\n",
       "Venturing                                                      250\n",
       "Expansion in existing market (product/service/geographical)    249\n",
       "Production-related actions                                     212\n",
       "Marketing                                                      205\n",
       "Divestiture                                                    199\n",
       "Human resources                                                161\n",
       "R&D-related actions                                            138\n",
       "Market entry                                                    76\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersample the data\n",
    "X_train_tf_idf_und, y_train_tf_idf_und = undersampler.fit_resample(X_train_tf_idf, y_train)\n",
    "y_train_tf_idf_und.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5589aef0",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93dcc951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_log_u'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9d54c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Results for tf_idf_log_u:\n",
      "Accuracy: 0.8402071388940263\n",
      "Precision: 0.36026114053500535\n",
      "Recall: 0.6700589186800374\n",
      "F1: 0.451167076851514\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_tf_idf_und, X_test_tf_idf, y_train_tf_idf_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f11fe7",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed135a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_DT_u'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c022125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1}\n",
      "Results for tf_idf_DT_u:\n",
      "Accuracy: 0.7222119474754948\n",
      "Precision: 0.2448431118673014\n",
      "Recall: 0.5589473780596214\n",
      "F1: 0.31730743145308793\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_tf_idf_und, X_test_tf_idf, y_train_tf_idf_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c137e",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de024bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_svm_u'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bef503d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'kernel': 'linear'}\n",
      "Results for tf_idf_svm_u:\n",
      "Accuracy: 0.8266136489735528\n",
      "Precision: 0.3335088284718865\n",
      "Recall: 0.6519299059132005\n",
      "F1: 0.4256100471788948\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_tf_idf_und, X_test_tf_idf, y_train_tf_idf_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca6c3d",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "641954fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_rf_u'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "180029de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 500}\n",
      "Results for tf_idf_rf_u:\n",
      "Accuracy: 0.7548548178287405\n",
      "Precision: 0.30445054840837427\n",
      "Recall: 0.599892873585511\n",
      "F1: 0.37733810372448\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_tf_idf_und, X_test_tf_idf, y_train_tf_idf_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5e84f9",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "956bd614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_ada_u'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e7b80f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.1, 'n_estimators': 250}\n",
      "Results for tf_idf_ada_u:\n",
      "Accuracy: 0.7200850749029036\n",
      "Precision: 0.23747518079421204\n",
      "Recall: 0.5434503359844656\n",
      "F1: 0.3065430654422951\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_tf_idf_und, X_test_tf_idf, y_train_tf_idf_und, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd2cd00",
   "metadata": {},
   "source": [
    "### 3.2.3 With oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "400769af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling technique\n",
    "resampling = 'Ove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4004573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                                                           38876\n",
       "Corporate \\ngovernance                                          9719\n",
       "New product introduction/\\nservice offering                     9719\n",
       "Merger & \\nacquisitions                                         9719\n",
       "Marketing                                                       9719\n",
       "Divestiture                                                     9719\n",
       "Strategic alliance                                              9719\n",
       "Financing                                                       9719\n",
       "Venturing                                                       9719\n",
       "R&D-related actions                                             9719\n",
       "Expansion in existing market (product/service/geographical)     9719\n",
       "Product/\\nservice improvement                                   9719\n",
       "Production-related actions                                      9719\n",
       "Human resources                                                 9719\n",
       "Market entry                                                    9719\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersample the data\n",
    "X_train_tf_idf_ove, y_train_tf_idf_ove = oversampler.fit_resample(X_train_tf_idf, y_train)\n",
    "y_train_tf_idf_ove.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823ed66e",
   "metadata": {},
   "source": [
    "#### A. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c02e2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_log_o'\n",
    "classifier = 'logR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cf9fafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Results for tf_idf_log_o:\n",
      "Accuracy: 0.9054928796005178\n",
      "Precision: 0.47242239937007435\n",
      "Recall: 0.5598527205536119\n",
      "F1: 0.5068324784317276\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, logreg, param_grid_log, X_train_tf_idf_ove, X_test_tf_idf, y_train_tf_idf_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf35ecf",
   "metadata": {},
   "source": [
    "#### B. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1fa0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_DT_o'\n",
    "classifier = 'DT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39715c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'criterion': 'gini', 'max_features': None, 'min_samples_leaf': 1}\n",
      "Results for tf_idf_DT_o:\n",
      "Accuracy: 0.8882004808581468\n",
      "Precision: 0.3925615862943295\n",
      "Recall: 0.4683849224334949\n",
      "F1: 0.42461885267251553\n"
     ]
    }
   ],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, tree, param_grid_DT, X_train_tf_idf_ove, X_test_tf_idf, y_train_tf_idf_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fdcb14",
   "metadata": {},
   "source": [
    "#### C. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f786c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_svm_o'\n",
    "classifier = 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, svm, param_grid_svm, X_train_tf_idf_ove, X_test_tf_idf, y_train_tf_idf_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e227def",
   "metadata": {},
   "source": [
    "#### D. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_rf_o'\n",
    "classifier = 'RF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, rfc, param_grid_rf, X_train_tf_idf_ove, X_test_tf_idf, y_train_tf_idf_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4decda1e",
   "metadata": {},
   "source": [
    "#### E. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model characteristics\n",
    "model_name = 'tf_idf_ada_o'\n",
    "classifier = 'ADA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa945c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a grid search for the logistic regression model\n",
    "# the results are automatically stored in results_all_df and best_params_dict\n",
    "perform_grid_search(model_name, ada, param_grid_ada, X_train_tf_idf_ove, X_test_tf_idf, y_train_tf_idf_ove, y_test,\n",
    "                   vectorizer, FS, classifier, resampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20807b",
   "metadata": {},
   "source": [
    "## 4. Write away results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e1356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write away results\n",
    "results_all_df.to_csv('./Output/Model performance/results_Vectorization.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dictionary with the best parameters away\n",
    "with open('./Output/parameters/Vectorization.json', 'w') as file:\n",
    "    json.dump(best_params_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eba666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
